[{"authors":["admin"],"categories":null,"content":"I am a Postdoctoral Researcher in Biostatistics at the MRC - Biostatistics Unit of University of Cambridge (UK). Here, I am part of the Design and Analysis of Randomised Trials (DART) Group and I work with Sofia Villar on developing and improving the statistical methodology for adaptive designs. More specifically, my focus is on the use of multi-armed bandit strategies for designing \u0026ldquo;more ethical\u0026rdquo; trials (i.e., with participants benefits) such as adaptive clinical trials and micro-randomized trials, a key feature of the emergent mobile-Health area. As such kind of experiments may have a dual (and competing) goal of improving outcomes for trial participants and learning about the effectiveness of interventions, estimation and inference in adaptively collected data play a central role in my research arena.\nI also actively collaborate with Bibhas Chakraborty and Joseph Jay Williams on other theoretical reinforcement learning works or more applied projects, respectively. Research questions include how to optimally design mobile apps for guiding users’ behavior and improving their health outcomes, or how to conduct educational experiments for improving students\u0026rsquo; performance.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nina-dl.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Postdoctoral Researcher in Biostatistics at the MRC - Biostatistics Unit of University of Cambridge (UK). Here, I am part of the Design and Analysis of Randomised Trials (DART) Group and I work with Sofia Villar on developing and improving the statistical methodology for adaptive designs. More specifically, my focus is on the use of multi-armed bandit strategies for designing \u0026ldquo;more ethical\u0026rdquo; trials (i.e., with participants benefits) such as adaptive clinical trials and micro-randomized trials, a key feature of the emergent mobile-Health area.","tags":null,"title":"Nina Deliu","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://nina-dl.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://nina-dl.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://nina-dl.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"e9c8298a2d61d01cfcd427699e57e570","permalink":"https://nina-dl.github.io/research_old/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/research_old/example/","section":"research_old","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"research_old"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://nina-dl.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":["machine learning","tidymodels"],"content":"  1 A sad script symphony 🎻 🎷 🎹 2 Packages 3 Data 4 Penguins 5 tidymodels 101 6 Hey Jude, don’t make it sad 🎶 7 Make it better   A few years ago, I did a talk called “Take a Sad Plot \u0026amp; Make it Better,” where I showed how I took a single sad plot and tried to make it better. The process of making that plot better taught me a lot about data visualization, and about the ggplot2 package.\nFast-forward to 2019 when I started learning tidymodels, and I have accumulated some pretty sad predictive modeling scripts! And my sad plots are not so lonely anymore. Specifically, my old scripts for doing cross-validation with tidymodels are particularly sad. But, I’ve been able to make them better (one might even call them happy), primarily due to changes in the tune package and the addition of the fit_resamples() function. The process of making these scripts better taught me a lot about predictive modeling, and about the (evolving) tidymodels ecosystem. So, why write a blog post with outdated code?\nI want to remember that I did this “by hand.” I want to remember how I did this “by hand.” The code still works, even if there is now a happier path to doing the same thing. I want to share cute penguin art and gifs.  Let’s start with some cute penguin art by Rohan Chakravarty…\n\nMy objective here is not to provide an introduction to using tidymodels, cross-validation, or to machine learning. If that is what you came for, check out the project button at the top of this post for my workshop materials for learners, and my associated blog post on the RStudio education site.\n Bottom line: If you are stumbling upon this blog post in the year 2020 or beyond, know that there is a better way!   1 A sad script symphony 🎻 🎷 🎹 I’m not the first person to write sad tidymodels scripts- there are many out in the wild. Here were the blog posts that I found most helpful when trying to solve this particular coding conundrum:\nModelling with Tidymodels and Parsnip: A Tidy Approach to a Classification Problem by Diego Usai\n A tutorial on tidy cross-validation with R by Bruno Rodrigues\n Modeling with parsnip and tidymodels by Benjamin Sorensen\n   2 Packages library(tidyverse) library(tidymodels) library(rpart) # for decision tree library(ranger) # for random forest  3 Data I’m going to use data that Allison Horst helped me source on penguins from the Palmer Station (Antarctica) Long Term Ecological Research Network.\n “sooo now I’m just looking at penguin pictures” - Allison Horst after slacking me this penguin data\n Here are the three dataset sources:\n Adelie penguins: https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.219.3 Chinstrap penguins: https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.220.3 Gentoo penguins: https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.221.2  I downloaded and imported these three datasets using R, then did some very light data wrangling and merged them into one called penguins, which I’ll use now:\npenguins \u0026lt;- read_csv( here::here(\u0026quot;content/post/2020-02-27-better-tidymodels/data/penguins.csv\u0026quot;)) %\u0026gt;% mutate_if(is.character, as.factor) #\u0026gt; Parsed with column specification: #\u0026gt; cols( #\u0026gt; species = col_character(), #\u0026gt; culmen_length_mm = col_double(), #\u0026gt; culmen_depth_mm = col_double(), #\u0026gt; flipper_length_mm = col_double(), #\u0026gt; body_mass_g = col_double(), #\u0026gt; sex = col_character() #\u0026gt; ) glimpse(penguins) #\u0026gt; Observations: 333 #\u0026gt; Variables: 6 #\u0026gt; $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade… #\u0026gt; $ culmen_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.… #\u0026gt; $ culmen_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.… #\u0026gt; $ flipper_length_mm \u0026lt;dbl\u0026gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 1… #\u0026gt; $ body_mass_g \u0026lt;dbl\u0026gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 380… #\u0026gt; $ sex \u0026lt;fct\u0026gt; MALE, FEMALE, FEMALE, FEMALE, MALE, FEMALE, MALE, F…  4 Penguins This data included structural size measurements of penguins like their bill length, flipper length, and body mass. It also included each penguin’s species and sex. I’m going to use this data to try to predict penguin body mass. Sadly, we only have data for three distinct penguin species:\npenguins %\u0026gt;% count(species) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Adelie 146 #\u0026gt; 2 Chinstrap 68 #\u0026gt; 3 Gentoo 119 Here is a lineup:\nFrom: https://www.bas.ac.uk/about/antarctica/wildlife/penguins/\nLooks like we have data for 3 of the smaller penguin species (of those pictured here).\nFirst, let’s build a simple linear regression model to predict body mass from flipper length.\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + geom_point(color = \u0026quot;salmon\u0026quot;, size = 3, alpha = .9) + geom_smooth(method = \u0026quot;lm\u0026quot;) + theme_penguin() Not bad! Looks promising. To actually fit a linear regression model, you might be used to something like this in R:\npenguin_mod \u0026lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins) summary(penguin_mod) #\u0026gt; #\u0026gt; Call: #\u0026gt; lm(formula = body_mass_g ~ flipper_length_mm, data = penguins) #\u0026gt; #\u0026gt; Residuals: #\u0026gt; Min 1Q Median 3Q Max #\u0026gt; -1057.33 -259.79 -12.24 242.97 1293.89 #\u0026gt; #\u0026gt; Coefficients: #\u0026gt; Estimate Std. Error t value Pr(\u0026gt;|t|) #\u0026gt; (Intercept) -5872.09 310.29 -18.93 \u0026lt;2e-16 *** #\u0026gt; flipper_length_mm 50.15 1.54 32.56 \u0026lt;2e-16 *** #\u0026gt; --- #\u0026gt; Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 #\u0026gt; #\u0026gt; Residual standard error: 393.3 on 331 degrees of freedom #\u0026gt; Multiple R-squared: 0.7621, Adjusted R-squared: 0.7614 #\u0026gt; F-statistic: 1060 on 1 and 331 DF, p-value: \u0026lt; 2.2e-16 But we aren’t going to stick with this. We are going to use tidymodels, with the goal of generating accurate predictions for future, yet-to-be-seen penguins.\n 5 tidymodels 101 The code provided in the section below is not particularly sad 🐧. If you are embarking on learning tidymodels, you’ll need to use this same kind of code as the building blocks for any predictive modeling pipeline.\n5.1 Parsnip: build the model This step is really three, using only the parsnip package:\nlm_spec \u0026lt;- linear_reg() %\u0026gt;% # pick model set_engine(\u0026quot;lm\u0026quot;) %\u0026gt;% # set engine set_mode(\u0026quot;regression\u0026quot;) # set mode lm_spec #\u0026gt; Linear Regression Model Specification (regression) #\u0026gt; #\u0026gt; Computational engine: lm Things that are missing: data (we haven’t touched it yet) and a formula (no data, no variables, no twiddle ~). This is an abstract model specification. See other possible parsnip models here.\n 5.2 Recipe: not happening here, folks This is where you would normally insert some code for feature engineering using the recipes package. But previously this required functions named prep(), bake(), juice()- so I’m willfully ignoring that for now. There will be no recipes involving penguins.\n 5.3 Rsample: initial split We’ll use the rsample package to split (ayee! I promise no penguins were hurt in the writing of this blog post) the penguins up into two datasets: training and testing. If you are unfamiliar with this practice, read up on the holdout method.\npenguin_split \u0026lt;- initial_split(penguins, strata = species) penguin_train \u0026lt;- training(penguin_split) penguin_test \u0026lt;- testing(penguin_split)  5.4 Fitting the model once Fitting a single model once is…not exactly the hardest part.\nThis is essentially the workflow from this early blog post.\nset.seed(0) lm_spec %\u0026gt;% # train: get fitted model fit(body_mass_g ~ ., data = penguin_train) %\u0026gt;% # test: get predictions predict(new_data = penguin_test) %\u0026gt;% # compare: get metrics bind_cols(penguin_test) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 297.  5.5 Fitting the model with a function If you squint, you might see that I could make this into a function like below:\nget_rmse \u0026lt;- function(model_spec, split) { model_spec %\u0026gt;% # train: get fitted model fit(body_mass_g ~ ., data = training(split)) %\u0026gt;% # test: get predictions predict(new_data = testing(split)) %\u0026gt;% # compare: get metrics bind_cols(testing(split)) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) } And I could use it to fit a linear regression model:\nset.seed(0) get_rmse(model_spec = lm_spec, split = penguin_split) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 297. I could also build up a tibble that includes the results, if I wanted to save the predicted values, for example:\nget_preds \u0026lt;- function(model_spec, split){ # train: get fitted model fit_model \u0026lt;- model_spec %\u0026gt;% fit(body_mass_g ~ ., data = training(split)) # test: get predictions preds \u0026lt;- fit_model %\u0026gt;% predict(new_data = testing(split)) %\u0026gt;% bind_cols(testing(split) %\u0026gt;% select(body_mass_g, species)) preds } set.seed(0) penguin_preds \u0026lt;- get_preds(model_spec = lm_spec, split = penguin_split) Then I can work with the predicted values, like plotting the fitted body mass estimates against the residuals.\nggplot(penguin_preds, aes(x = .pred, y = (.pred - body_mass_g))) + geom_point(aes(colour = species), size = 3, alpha = .8) + geom_smooth(method = \u0026quot;lm\u0026quot;) + theme_penguin() + scico::scale_colour_scico_d(end = .8) + ggtitle(\u0026quot;Residuals vs Fitted\u0026quot;) #\u0026gt; `geom_smooth()` using formula \u0026#39;y ~ x\u0026#39;  # compare: get metrics penguin_preds %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 297. Or I could fit a regression tree model with a new model spec:\n# regression tree model spec rt_spec \u0026lt;- decision_tree() %\u0026gt;% set_engine(\u0026quot;rpart\u0026quot;) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) # get rmse set.seed(0) get_preds(model_spec = rt_spec, split = penguin_split) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 321. Or a random forest:\n# random forest model spec rf_spec \u0026lt;- rand_forest() %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) # get rmse set.seed(0) get_preds(model_spec = rf_spec, split = penguin_split) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 299. But, unfortunately, I shouldn’t be predicting with the test set over and over again like this. It isn’t good practice to predict with the test set \u0026gt; 1 time. What is a good predictive modeler to do? I should be saving (holding out) the test set and use it to generate predictions exactly once, at the very end — after I’ve compared different models, selected my features, and tuned my hyperparameters. How do you do this? You do cross-validation with the training set, and you leave the testing set for the very last fit you do.\n  6 Hey Jude, don’t make it sad 🎶 Now, for the 😭 part- let’s add cross-validation! To do this, we’ll use a function called rsample::vfold_cv().\n# add the cv step here set.seed(0) penguin_folds \u0026lt;- vfold_cv(data = penguin_train, strata = \u0026quot;species\u0026quot;) penguin_folds #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 2 #\u0026gt; splits id #\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 The process of training, testing, and computing metrics gets a lot harder when you need to do this across 10 folds, each with a different data split. I eventually worked out three approaches, which I show below. All require some level of comfort with iteration using the purrr package.\n6.1 Function with minimal purrr-ing This approach is essentially a mega-function, that we then use purrr to map across each fold.\nI’m going to change a few things from my previous get_preds() function:\ntraining(split) -\u0026gt; analysis(split) testing(split) -\u0026gt; assessment(split) I also added the rsample::add_resample_id() function to keep track of the fold number. I saved the predictions now as a list column.  To build up this function, my strategy was to figure out how to work with one fold, then I knew I’d be able to use purrr::map_df() to apply it across multiple folds.\n# Figure it out for one fold get_fold_results \u0026lt;- function(model_spec, split){ # train: get fitted model for each fold fits \u0026lt;- model_spec %\u0026gt;% fit(body_mass_g ~ ., data = analysis(split)) # test: get predictions on for each fold preds \u0026lt;- fits %\u0026gt;% predict(new_data = assessment(split)) %\u0026gt;% bind_cols(assessment(split)) # compare: compute metric for each fold rmse \u0026lt;- assessment(split) %\u0026gt;% summarize(rmse = rmse_vec(truth = body_mass_g, estimate = preds$.pred)) rmse %\u0026gt;% # add fold identifier column rsample::add_resample_id(split = split) %\u0026gt;% as_tibble() %\u0026gt;% # add predictions mutate(preds = list(preds)) } I tried this function with a single fold first:\nset.seed(0) get_fold_results( split = penguin_folds$splits[[1]], model_spec = rt_spec ) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; rmse id preds #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 291. Fold01 \u0026lt;tibble [26 × 7]\u0026gt; Next, I used purrr- but just once. The function get_fold_results is doing most of the work for us, but I needed purrr to map it across each fold.\nset.seed(0) kfold_results \u0026lt;- map_df( penguin_folds$splits, ~get_fold_results(.x, model = rt_spec)) kfold_results #\u0026gt; # A tibble: 10 x 3 #\u0026gt; rmse id preds #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 291. Fold01 \u0026lt;tibble [26 × 7]\u0026gt; #\u0026gt; 2 298. Fold02 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 3 303. Fold03 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 4 359. Fold04 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 5 320. Fold05 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 6 434. Fold06 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 7 320. Fold07 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 8 245. Fold08 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 9 262. Fold09 \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 10 343. Fold10 \u0026lt;tibble [25 × 7]\u0026gt; Here we are still left with 10 RMSE values- one for each of the 10 folds. We don’t care too much about by fold- the power is in the aggregate. Specifically, we mainly care about the central tendency and spread of these RMSE values. Let’s finish by combining (or aggregating) these metrics.\nkfold_results %\u0026gt;% summarize(mean_rmse = mean(rmse), sd_rmse = sd(rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 317. 53.4 So, this works. But, can you imagine doing it again? Without errors? Can you imagine teaching it?\n 6.2 Purrr-to-the-max This approach is purrr::map() (and friends) on steriods. We use vanilla map(), map2(), and map2_dbl() here. We also use anonymous functions as a formula, and the pipe operator within those anonymous functions.\nset.seed(0) penguin_res \u0026lt;- penguin_folds %\u0026gt;% mutate( # train: get fitted model for each fold train_set = map(splits, analysis), fit_models = map(train_set, ~rt_spec %\u0026gt;% fit(body_mass_g ~ ., data = .x)), # test: get predictions for each fold test_set = map(splits, assessment), estimates = map2(fit_models, test_set, ~.x %\u0026gt;% predict(.y)), # compare: compute metric for each fold rmse = map2_dbl(test_set, estimates, ~rmse_vec(truth = .x$body_mass_g, estimate = .y$.pred)) ) penguin_res #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 7 #\u0026gt; splits id train_set fit_models test_set estimates rmse #\u0026gt; * \u0026lt;named lis\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;named lis\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [22… Fold01 \u0026lt;tibble [225 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26… \u0026lt;tibble [26… 291. #\u0026gt; 2 \u0026lt;split [22… Fold02 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 298. #\u0026gt; 3 \u0026lt;split [22… Fold03 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 303. #\u0026gt; 4 \u0026lt;split [22… Fold04 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 359. #\u0026gt; 5 \u0026lt;split [22… Fold05 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 320. #\u0026gt; 6 \u0026lt;split [22… Fold06 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 434. #\u0026gt; 7 \u0026lt;split [22… Fold07 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 320. #\u0026gt; 8 \u0026lt;split [22… Fold08 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 245. #\u0026gt; 9 \u0026lt;split [22… Fold09 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 262. #\u0026gt; 10 \u0026lt;split [22… Fold10 \u0026lt;tibble [226 … \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25… \u0026lt;tibble [25… 343. penguin_res %\u0026gt;% summarise(mean_rmse = mean(rmse), sd_rmse = sd(rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 317. 53.4  6.3 The purrr mash-up Another way I worked out was largely after reviewing Max’s slides from previous workshops. This is basically a mash-up of my previous two approaches, where we write laser-focused functions that each do one thing, then use purrr to apply those functions across the folds. This way is nice(r) for showing in slides as you can incrementally build up the results table. Let’s see this sad script in action…\n6.3.1 Round 1 set.seed(0) # for reproducibility # train: get fitted model for a split get_fits \u0026lt;- function(split, model_spec){ model_spec %\u0026gt;% fit(body_mass_g ~ ., data = analysis(split)) } # train: get fitted models across folds penguin_purrr \u0026lt;- penguin_folds %\u0026gt;% mutate(rt_fits = map(splits, get_fits, rt_spec)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 3 #\u0026gt; splits id rt_fits #\u0026gt; * \u0026lt;named list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;named list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt;  6.3.2 Round 2 # test: get predictions for a split get_preds \u0026lt;- function(split, fit_df) { fit_df %\u0026gt;% predict(new_data = assessment(split)) %\u0026gt;% bind_cols(assessment(split)) } # test: get predictions across folds penguin_purrr \u0026lt;- penguin_purrr %\u0026gt;% mutate(rt_preds = map2(splits, rt_fits, get_preds)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 4 #\u0026gt; splits id rt_fits rt_preds #\u0026gt; * \u0026lt;named list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;named list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 × 7]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt;  6.3.3 aaaand Round 3 # compare: compute metric for a split get_rmse \u0026lt;- function(pred_df) { pred_df %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) %\u0026gt;% pluck(\u0026quot;.estimate\u0026quot;) } # compare: compute metric across folds penguin_purrr \u0026lt;- penguin_purrr %\u0026gt;% mutate(rt_rmse = map_dbl(rt_preds, get_rmse)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 5 #\u0026gt; splits id rt_fits rt_preds rt_rmse #\u0026gt; * \u0026lt;named list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 × 7]\u0026gt; 291. #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 298. #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 303. #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 359. #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 320. #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 434. #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 320. #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 245. #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 262. #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 343. Finally, summarizing as I did before:\npenguin_purrr %\u0026gt;% summarize(mean_rmse = mean(rt_rmse), sd_rmse = sd(rt_rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 317. 53.4 In practice, if you did all these at once instead of incrementally, it would look like:\nset.seed(0) penguin_folds %\u0026gt;% # train: get fitted model for a split mutate(rt_fits = map(splits, get_fits, rt_spec)) %\u0026gt;% # test: get predictions on for each fold mutate(rt_preds = map2(splits, rt_fits, get_preds)) %\u0026gt;% # compare: compute metric for each fold mutate(rt_rmse = map_dbl(rt_preds, get_rmse)) #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 5 #\u0026gt; splits id rt_fits rt_preds rt_rmse #\u0026gt; * \u0026lt;named list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;named list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 × 7]\u0026gt; 291. #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 298. #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 303. #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 359. #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 320. #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 434. #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 320. #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 245. #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 262. #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 × 7]\u0026gt; 343. When you put it like that, it doesn’t look like so much work! But, this way hides how much work it takes to write those 3 custom functions: get_fits(), get_preds(), and get_rmse(). And we still had to use vanilla map(), map2(), and map2_dbl().\n   7 Make it better I kept a learning log while working through the all the above code, and I wrote down these notes to myself:\nIt is very easy to do the wrong thing; it is very hard to do the right thing.\n I lost sight many times of what the code I was writing was doing, because I was using up so much cognitive energy on getting the code to just work.\n I thought I knew how to use purrr…\n  If you have made it this far, I’m pretty sure I don’t need to convince you that a better way to do cross-validation using tidymodels would be more pleasant to do more than once. It would also be less prone to error due to me copying-and-pasting repeatedly, and making stupid mistakes that would be difficult to spot with so much cluttered code. Luckily, tune::fit_resamples() came along to take a sad script and make it better:\npenguin_party \u0026lt;- tune::fit_resamples( body_mass_g ~ ., model = rt_spec, resamples = penguin_folds ) Here is the beautiful output from that function:\npenguin_party #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 4 #\u0026gt; splits id .metrics .notes #\u0026gt; * \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;tibble [2 × 3]\u0026gt; \u0026lt;tibble [0 × 1]\u0026gt; Now, to see all the stuff inside this penguin_party, we can use tune’s collect_* functions.\npenguin_party %\u0026gt;% collect_metrics() #\u0026gt; # A tibble: 2 x 5 #\u0026gt; .metric .estimator mean n std_err #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 317. 10 16.9 #\u0026gt; 2 rsq standard 0.827 10 0.0303 To see the predictions, we need to add use control_resamples():\npenguin_party \u0026lt;- tune::fit_resamples( body_mass_g ~ ., model = rt_spec, resamples = penguin_folds, control = control_resamples(save_pred = TRUE) # add this line ) Then we collect the predictions.\npenguin_party %\u0026gt;% collect_predictions() #\u0026gt; # A tibble: 251 x 4 #\u0026gt; id .pred .row body_mass_g #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 Fold01 4040. 4 4675 #\u0026gt; 2 Fold01 3428. 11 3800 #\u0026gt; 3 Fold01 3428. 14 3200 #\u0026gt; 4 Fold01 4040. 41 3750 #\u0026gt; 5 Fold01 4040. 54 3900 #\u0026gt; 6 Fold01 3428. 65 3400 #\u0026gt; 7 Fold01 3428. 70 2900 #\u0026gt; 8 Fold01 4040. 71 4100 #\u0026gt; 9 Fold01 3428. 76 2925 #\u0026gt; 10 Fold01 4040. 85 3775 #\u0026gt; # … with 241 more rows Now, isn’t that better?\n ","date":1582761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"6b69e5ca6732b982a2d9b7db27a31414","permalink":"https://nina-dl.github.io/post/2020-02-27-better-tidymodels/","publishdate":"2020-02-27T00:00:00Z","relpermalink":"/post/2020-02-27-better-tidymodels/","section":"post","summary":"Taking a sad script and making it better for model cross-validation.","tags":["tidymodels"],"title":"Take a Sad Script \u0026 Make it Better: Tidymodels Edition","type":"post"},{"authors":[],"categories":[],"content":" I’m excited to be teaching a new workshop at the upcoming rstudio::conf in January called “Introduction to Machine Learning with the Tidyverse”, with my colleague Garrett Grolemund. Our workshop just sold out over the weekend! 🎉\nIt is always hard to develop an entirely new workshop, especially if you are doing it at the same time as learning how to use a new API. It is even harder when that API is under active development like the tidymodels ecosystem! I’ve been so lucky to be able to work with the tidymodels team at RStudio, Max Kuhn and Davis Vaughan, to help shape how we tell the tidymodels story to ML beginners. But my favorite part of developing a new workshop like this has been studying how others teach machine learning. Spoiler alert: there are a lot of materials intended for learners that make things seem harder than they actually are! Below, I’m sharing my bookmarked resources, organized roughly in the order I think they are most helpful for beginners.\nMachine Learning for Everyone. In simple words. With real-world examples. Yes, again. In my experience, the biggest hurdle to getting started is sifting through both the hype and the math. This is a readable illustrated introduction to key concepts that will help you start building your own mental model of this space. For example, “the only goal of machine learning is to predict results based on incoming data. That’s it.” There you go! Start here.\n\n A Visual Introduction to Machine Learning by r2d3. This is a wonderful two-part series (that I wish would be extended!):\n Part I: A Decision Tree Part II: Model Tuning and the Bias-Variance Tradeoff   Supervised Machine Learning course by Julia Silge Taught with R and the caret package (the precursor to the in-development tidymodels ecosystem), this is a great next step in your machine learning journey as you’ll start doing ML right away in your browser using an innovative course delivery platform. You’ll also get to play with data that is not iris, titanic, or AmesHousing. This will be sweet relief because you’ll find the rest of my recommended resources all basically build models to predict home prices in Ames, Iowa.\n\n Hands-on Machine Learning with R by Bradley Boehmke \u0026amp; Brandon Greenwell. Another great way to learn concepts plus code, although another one that focuses on the caret package (pre-tidymodels). Each chapter maps onto a new learning algorithm, and provides a code-through with real data from building to tuning. The authors also offer practical advice for each algorithm, and the “final thoughts” sections at the end of each chapter will help you tie it all together.\n\nDon’t skip the “Fundamentals” section, even if you feel like you’ve got that down by now. The second chapter on the modeling process is especially good.\n\n Interpretable Machine Learning: A Guide for Making Black Box Models Explainable by Christoph Molnar. If you only have time to read a single chapter, skip ahead to Chapter 4: Interpretable Models. I also appreciated the introduction section on terminology. But the whole book is excellent and well-written.\n\n Model evaluation, model selection, and algorithm selection in machine learning- a 4-part series by Sebastian Raschka. I found this to be a great evidence-based, thorough overview of the methods for machine learning. I especially liked how he walks you step-by-step from the simplest methods like the holdout method up to nested cross-validation:\n Part I: The Basics Part II: Bootstrapping \u0026amp; uncertainties Part III: Cross-validation and hyperparameter tuning Part IV: Comparing the performance of machine learning models and algorithms using statistical tests and nested cross-validation   At this point, if you can read through the above resources and you are no longer feeling awash in new terminology, I think your vocabulary and mental model are in pretty good shape! That means you are ready for the next step, which is to read Max Kuhn and Kjell Johnson’s new book Feature Engineering and Selection: A Practical Approach for Predictive Models\n\nIn my experience, the later chapters in this book filled in a lot of lingering questions I had about certain methods, like whether to use factor or dummy variables in tree-based models. But also don’t miss the section on “important concepts” at the beginning- this should feel like a nice review if you’ve gotten this far!\n Elements of Statistical Learning. The entire PDF of the book is available online. A great resource for those with a strong statistics background, and for those looking for more math and formulas.\n  Other note-worthy resources  For the highly visual learner, you may want to cue up some YouTube videos from Udacity’s “Machine Learning for Trading” course. I found these illustrations especially helpful:\n Cross-validation Overfitting Ensemble learners Bootstrap aggregating (bagging) Boosting   Chris Albon’s Machine Learning Flashcards ($12)\n Shirin Elsinghorst’s blog (free! and so good).\n\nI love her sketchnotes.\n I also found Rafael Irizarry’s “Introduction to Machine Learning”, a chapter from his Introduction to Data Science book, to have some helpful discussion.\n Machine Learning: A primer by Danilo Bzdok, Martin Krzywinski \u0026amp; Naomi Altman, from the Nature Methods Points of Significance collection- this collection in general is always straight-forward with great visuals. Start with the primer, then skim these:\n Statistics versus machine learning Machine learning: supervised methods Classification and regression trees (decision trees are the “base learner” for many ensemble methods - this is a good intro) Ensemble methods: bagging and random forests    That’s all for now- if you are taking my workshop in January I look forward to meeting you in person! If not, rest assured that all code and materials will be shared openly after the workshop. Until then, happy learning 🤖\n ","date":1577059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577119901,"objectID":"416351d525a4abd88ecf05ec88076d80","permalink":"https://nina-dl.github.io/post/2019-12-23-learning-to-teach-machines-to-learn/","publishdate":"2019-12-23T00:00:00Z","relpermalink":"/post/2019-12-23-learning-to-teach-machines-to-learn/","section":"post","summary":"I’m excited to be teaching a new workshop at the upcoming rstudio::conf in January called “Introduction to Machine Learning with the Tidyverse”, with my colleague Garrett Grolemund. Our workshop just sold out over the weekend! 🎉\nIt is always hard to develop an entirely new workshop, especially if you are doing it at the same time as learning how to use a new API. It is even harder when that API is under active development like the tidymodels ecosystem!","tags":[],"title":"Learning to Teach Machines to Learn","type":"post"},{"authors":["Nina Deliu"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://nina-dl.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":"  #1: Update Hugo #2: Change the baseurl #3: Netlify drag-and-drop #4: Torch public/ #5: Peruse public/ #6: Back to the future    “Just a spoonful of Hugo helps the blog go down.” - me, only somewhat kidding\n In this series, I’m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated). You can read the previous posts about my “Spoonful of Hugo” series about Hugo archetypes, Hugo versions, and Hugo page bundles.\nThe following are a few steps that I always start with to troubleshoot any blogdown/Hugo/Netlify problems. These steps would solve what I would anecdotally estimate as ~50% of blogdown problems that I see posted in the GitHub repository and on the community site.\n#1: Update Hugo  Figure 1: Don’t be like this  If things have gone south and you are getting Hugo errors when you use the “Serve Site” Addin locally, it is possible that you need to update your version of Hugo. From R, you can check your Hugo version with blogdown:\nblogdown::hugo_version() Then you can reference your Hugo theme to find the minimum version of Hugo required by your theme:\n Figure 2: Check your theme’s minimum Hugo version  You can go higher than the minimum version though, so it’s good practice to update your Hugo, again from within R:\nblogdown:: update_hugo() Check your version again post-update:\nblogdown::hugo_version() ## [1] \u0026#39;0.55.6\u0026#39; If you are using Netlify to build your site using Hugo, you’ll want this version to match that- the best way to do that is with a netlify.toml file.\n #2: Change the baseurl Open up your config.toml file and look for the baseurl field, usually pretty close to the top. Here is mine1:\nbaseurl = \u0026quot;https://alison.rbind.io\u0026quot; Now if you are just starting with Hugo and don’t actually have a domain name yet, try taking the advice that blogdown automatically prints out for you:\nWarning: You should change the \u0026quot;baseurl\u0026quot; option in config.toml from https://example.org to your actual domain; if you do not have a domain, set \u0026quot;baseurl\u0026quot; to \u0026quot;/\u0026quot; But be careful here- you shouldn’t leave it as “/”- once you do have your domain name you should update the baseurl as “/” is a not a valid URL.\nCare to know more? Here is a quote from the person who writes the Hugo docs:\n “…the only purpose for the baseurl field in the config is to define the full base URL of your website for deployment purposes.” - @rdwatters\n The main error that would happen without the trailing slash in the past is that you would end up with a site where the theme’s CSS would be all wrong. This was probably because the theme designer used code like this buried in a layout file:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ .Site.BaseURL }}css/style.css\u0026quot;/\u0026gt; Now, if you set baseurl = \u0026quot;http://mysite.com\u0026quot; but only rendered locally, things would look just peachy, because the default local server already included the trailing slash. So, the link in the html file would be2:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;http://localhost:1313/css/style.css\u0026quot;\u0026gt; But, at build, the link in the html file would turn into:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;http://mysite.comcss/style.css\u0026quot;\u0026gt; Which creates sites that look like this:\n Figure 3: Hugo tranquil peak theme  GitHub issue #369\n Figure 4: Hugo universal theme  GitHub issue #131\nGitHub issue #114\nHowever, Hugo authors and theme developers have largely been moving towards using relative URLs instead of the baseurl to build paths. This was based on public advice voiced by the Hugo authors on the discourse forum. For example:\n “The recommended way to reference resources is to use either relURL or absURL template funcs, which handles the slash issues.”- @bep\n Following that advice, a more up-to-date theme would have code that looks like this buried in a layout file:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ \u0026quot;css/style.css\u0026quot; | relURL }}\u0026quot;/\u0026gt; →  Bottom line? If your theme uses relURL or absURL to link to site resources like CSS, JavaScript, or static images, then whether or not you include a trailing slash in your baseurl should not matter at all.\nAnd here is some tough love about your theme: if the most recent version does still require the trailing slash in the baseurl to “work” out of the box, I would seriously consider switching themes. This is a pretty good “canary in the coal mine” test regarding how up-to-date the theme author is, and how well the theme you have chosen adheres to Hugo templating best practices. If you are having pain with this now, it is likely not the only thing that will be painful about working with your theme.\n  #3: Netlify drag-and-drop If you can render your site locally but your published site looks different, try the drag-and-drop method:\nUse the “Serve Site” Addin, then drag-and-drop the public/ folder straight into Netlify. What does this do? You can now see your public site…that you built…with your local version of Hugo. Netlify is doing none of the site building here.\nOne of the first benefits of this approach is that it ensures that you are able to actually generate a public/ folder locally! I have seen folks struggle to deploy the wrong repo. This simple step can force you to make sure to use the “Serve Site” Addin to generate the public/ folder, and that the repo you are trying to link to Netlify actually contains a Hugo site because you must physically move the public/ folder. But this method can also help you diagnose other problems too.\nIf your public/ folder does not render on Netlify, you have work to do locally. I can’t tell you what it is as it can be a number of things, but you can be sure that your problem is not just the Netlify build- it is your local build too.\nIf your public/ folder does render perfectly on Netlify, but you are getting a Netlify build error, then you likely have a Hugo version problem. It might be that the version you are running locally is more recent than the version run by Netlify by default to actually build your site. The good news is there is a quick fix for this! The solution is to upgrade the Hugo version Netlify is using- see my advice here for how to do that.\nIf you are happy with how your site looks but you are missing content and/or seeing old deleted content, then you may need the next few strategies to troubleshoot.\n #4: Torch public/ When you are seeing very weird things locally, try deleting your local public/ folder. Then serve site again. Sometimes it can get “junked up”. I’ve found that sometimes deleted content can be a little sticky. As recommended in the blogdown book:\n “you are strongly recommended to delete the /public/ directory before you rebuild the site for publishing every time, because Hugo never deletes it”\n Also, this has a bonus of reinforcing for you exactly what the “Serve Site” Addin does - it regenerates the public/ folder. This is also the folder that, if you are using Netlify to build your site, is in your .gitignore file because Netlify (+ Hugo) generates this file “fresh” with each push to your GitHub repository.\n #5: Peruse public/ When you notice weird things, try actually looking inside public/- don’t be afraid to spelunk around in there! If you are seeing something wrong with your site, try to figure out how blogdown/Hugo is processing and rendering your content. This folder can tell you a lot! Keep in mind that your local public/ folder will still contain future/draft/expired content if you used the “Serve Site” Addin.\n #6: Back to the future  Figure 5: Where are my posts?  If your site renders beautifully locally, and your drag-and-drop site from public/ looks the same, but you are missing key content when you actually deploy to Netlify using a Hugo build, you may have inadvertently stumbled into a Hugo date time warp. This is a fairly common gotcha. Try using the drag-and-drop method again, this time first delete public/, then instead of using the “Serve Site” Addin, run this in your console:\nblogdown::build_site(local = FALSE) Plop this new public folder in Netlify to see what your site will look like when it is actually published. What does this show you? Your local Hugo build (read: your public/ folder generated by “Serve Site”) differs by design in 3 important ways from your deployed site built by Netlify/Hugo. By default, Hugo will not publish:\n Content with a future publishDate value\n Content with draft: true status\n Content with a past expiryDate value\n  You can see that these are defaults. The behavior of the “Serve Site” Addin is also documented in the blogdown book:\n “This is for you to preview draft and future posts locally.”\n Blogdown’s build_site(local = FALSE) differs from the “Serve Site” Addin in that it will not render draft, future, or expired content. So your public/ folder from build_site(local = FALSE) shows you exactly what Netlify should publish. Seeing it can help you troubleshoot why some content was showing up locally but not when you publish.\nThe defaults are pretty sensible and nice to have, as you can still put these kinds of content under version control, and hence collaborate with other team members on the content without having the content publish (or expire) until you say so.\nTo show content that Hugo was hiding, you’ll want to edit some YAML fields in the individual offending content files. For example, in the YAML of an individual content file (like a blog post), if you want to un-draft it, add or change this key/value:\ntitle: \u0026#39;A Spoonful of Hugo: Troubleshooting your Build\u0026#39; author: \u0026quot;Alison Hill\u0026quot; date: \u0026#39;2019-03-04\u0026#39; draft: false Alternatively, if you want to date something in the future (like to advertise the date of an upcoming talk) but publish now, you can use the publishDate field. The publishDate field is a newer addition to Hugo (\u0026gt;= v0.54.0) which, if left unset, will default to the date field, which means in the individual content file YAML you can do:\ntitle: \u0026#39;A Spoonful of Hugo: Get excited!!\u0026#39; author: \u0026quot;Alison Hill\u0026quot; date: \u0026#39;2025-03-04\u0026#39; publishDate: \u0026#39;2019-03-04\u0026#39; Hopefully these 6 things can help you get unstuck. If not, the RStudio community forums are a great place to ask questions!\n  Yes that’s right, I don’t have a trailing slash- read on for why I can get away with this.↩\n https://discourse.gohugo.io/t/how-not-to-specify-url-site/5691/5↩\n   ","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"0ba13389195341f445a9a6be1766a7ec","permalink":"https://nina-dl.github.io/post/2019-03-04-hugo-troubleshooting/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/2019-03-04-hugo-troubleshooting/","section":"post","summary":"A few troubleshooting strategies to save your sanity","tags":["blogdown"],"title":"A Spoonful of Hugo: Troubleshooting Your Build","type":"post"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":"  “Just a spoonful of Hugo helps the blog go down.” - me, only somewhat kidding\n In this series, I’m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated). You can read the previous posts about my “Spoonful of Hugo” series about Hugo archetypes and Hugo versions.\nThis is my third post in this series and it is breaking news.\nHugo Page Bundles Well, not really breaking news, but you still may not know about it! Hugo v0.32 introduced a new feature called Page Bundles, as a way to organize the content files. Blogdown users rejoice that Davis Vaughn posted an issue on the rstudio/blogdown repo to enable this option, which Yihui added shortly before rstudio::conf 2019 🎉. Here is the snippet from the NEWS.md:\n “One benefit of using a page bundle instead of a normal page is that you can put resource files associated with the post (such as images) under the same directory of the post itself. This means you no longer have to put them under the static/ directory, which has been quite confusing to Hugo beginners.”\n What does a blogdown/Hugo site begin to look like without page bundles? I think here is a representative example from tidyverse.org (sorry tidyverse team- it’s not you, it’s the old Hugo).\nFor this team, they need an image for every post, which gets out of control pretty fast. Also, some ended up in static/ too, organized by post (which I have done on my own blog, though not well or consistently).\nWhat would it look like to use page bundles?\ncontent/ ├── about │ ├── index.md ├── posts │ ├── 2015-07-23-hi-world │ │ ├── bakers.csv │ │ ├── image1.jpg │ │ ├── image2.png │ │ └── index.Rmd │ └── 2015-07-24-bye-world │ └── index.Rmd One could call this bundled file structure “tidier” 🍱.\nIn the above, after serving site, index.html files also get added to the bundle. In Hugo’s terms, these are leaf bundles. The resource files allowed in a bundle include page and non-page items like images, pdf, .csv files, etc.\nThis is instead of:\ncontent/ ├── about │ ├── index.md ├── posts │ ├── 2015-07-23-hi-world.Rmd │ ├── bakers.csv │ ├── image1.jpg │ ├── image2.png │ └── 2015-07-24-bye-world.Rmd When you create a new bundled post, the actual content of the post goes in the index file of a page bundle. So:\n# not bundled post post/2015-07-23-hi-world.Rmd # bundled post post/2015-07-24-bye-world/index.Rmd  Bundle Me, blogdown! First, read the previous post on setting up a netlify.toml file. Since using Hugo page bundles depends on Hugo v0.32 or higher, you should go ahead and update hugo then update your netlify.toml with your updated version:\nblogdown::update_hugo() blogdown::hugo_version() Now, let’s use the usethis package.\nProject-specific .Rprofile First, I’m going to demo here how to create a project-specific .Rprofile file- but know that you can do a user-level .Rprofile file too.\n# install.packages(\u0026quot;usethis\u0026quot;) # uncomment this to install usethis::edit_r_profile(scope = \u0026quot;project\u0026quot;) These helpful messages should print to your console: please note the “restart” reminder…\n\u0026gt; usethis::edit_r_profile(scope = \u0026quot;project\u0026quot;) ● Restart R for changes to take effect ✔ Setting active project to \u0026#39;/Users/alison/rprojs/alison.rbind.io\u0026#39; ● Modify \u0026#39;.Rprofile\u0026#39; Now you could add this to your file:\n# in .Rprofile of the website project if (file.exists(\u0026quot;~/.Rprofile\u0026quot;)) { base::sys.source(\u0026quot;~/.Rprofile\u0026quot;, envir = environment()) } options(blogdown.new_bundle = TRUE) The first code chunk above is from the blogdown book, where we describe a workaround for loading both user and project .Rprofile files (since R technically only reads one startup profile file).\nIf you don’t want this, you could add the blogdown options to your user .Rprofile instead using:\nusethis::edit_r_profile(scope = \u0026quot;user\u0026quot;) Heck, while you are at it, you could set a bunch of options to make your blogdown life easier:\n# in .Rprofile of the website project if (file.exists(\u0026quot;~/.Rprofile\u0026quot;)) { base::sys.source(\u0026quot;~/.Rprofile\u0026quot;, envir = environment()) } options( blogdown.author = \u0026quot;Alison Hill\u0026quot;, blogdown.ext = \u0026quot;.Rmd\u0026quot;, blogdown.subdir = \u0026quot;post\u0026quot;, blogdown.yaml.empty = TRUE, blogdown.new_bundle = TRUE, blogdown.title_case = TRUE ) For the blogdown-specific options, any of these prepopulate content in your “New Post” Addin (I told you to use this here). There is a handy table from the blogdown book, summarized here:\n blogdown.author = author of new posts blogdown.ext = default extension of new posts (can also be “.md” or “.Rmarkdown”) blogdown.subdir = theme-specific, you need to know your theme and content folder here blogdown.yaml.empty = I told you to do that here blogdown.new_bundle = what this whole post is about! blogdown.title_case = “nEed More coFFee” –\u0026gt; “Need More Coffee” (it tidies all your post titles to title case)   The Newline Thing Here is a massive .Rprofile gotcha: this file must end with a blank line. So make sure you add an empty line at the end of the file, then save it, and restart your R session.\nWant to make your general R life easier in the future? Follow Yihui’s advice and do this in RStudio to ensure that all source files end with a newline:\n  Use Bundles After restarting R, try using the “New Post” Addin, this time with feeling. There is still one more gotcha though. Use the Addin to create your new bundled post. The only catch is that once you are looking at your exciting new post, you should delete the slug in the YAML (I posted an issue about this here).\nThe reason is that you want the link to your post to be:\nhttp://alison.rbind.io/post/2019-02-21-hugo-page-bundles/\nIf you include the slug, the link to your post will be:\nhttp://alison.rbind.io/post/2019-02-21-hugo-page-bundles/hugo-page-bundles\nAnother option is to update your config.toml file with permalinks like Yihui suggests (but beware: this will change all your past links as well, requiring some Netlify redirects):\n[permalinks] post = \u0026quot;/:year/:month/:day/:slug/\u0026quot; The default here from Hugo was /post/:year-:month-:day-:slug/:slug/.\nA small note: if you want to add relative links from a blog post to another post in your same blog. So [this](/post/2019-02-19-hugo-archetypes/) becomes this.\nNow, add images and data files to your ❤️’s content! But you may want to do one more thing…\n Update Metadata If you are anything like me, you may draft a blog post then come back to it later. For example, I started this post 2 days ago, but want to publish it today, 2019-10-03. The cool thing that was already built-in to blogdown is the “Update Metadata” Addin. With your blog post open (it should be called index.Rmd)1, click on Addins and select “Update Metadata”. You should see a window like this:\nCheck the box to rename the file if the date has changed. RStudio will tell you your file has been deleted- which is technically true since the folder was renamed, but don’t panic!\nClick YES. The index.Rmd file that is now open should have an updated date field in the YAML. In your RStudio file viewer, you may want to click on “content” at this point then navigate back to view your post- then you will then see that the folder name now has an updated date too.\n  If no post is open, you will get an error: Warning message: The current document does not seem to contain YAML metadata↩︎\n   ","date":1550707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550707200,"objectID":"57794aaa1dd7911236dd044032a33bf8","permalink":"https://nina-dl.github.io/post/2019-02-21-hugo-page-bundles/","publishdate":"2019-02-21T00:00:00Z","relpermalink":"/post/2019-02-21-hugo-page-bundles/","section":"post","summary":"Why (and how) you should use Hugo's new page bundles feature","tags":["blogdown"],"title":"A Spoonful of Hugo: Page Bundles","type":"post"},{"authors":["alison"],"categories":["blogdown","netlify","hugo"],"content":"  “Just a spoonful of Hugo helps the blog go down.” - me, only somewhat kidding\n You can read the previous post about my “Spoonful of Hugo” series here. In this series, I’m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated).\nThis is my second post in this series, and it is a relatively quick one. Just do this. This one is a no-brainer.\n Thanks to Mara Averick for alerting me that with Hugo version 0.54.0 and onward, there is a trailing zero at the end of Hugo versions now. So for versions before 0.54.0, use the format: 0.53; for later versions use 0.54.0 (0.54 will not work).   Use Netlify to Deploy First, you’ll need to use Netlify! I am a very happy Netlify user and currently have approximately 33 sites deployed. To setup a new account, navigate to Netlify and click on the Sign Up link.\nSign up with GitHub to connect your GitHub and Netlify accounts (as shown below).\nIf you use a different version control service, select GitLab or BitBucket instead.\nThe last step is to use the Netlify UI in browser do New Site from Git \u0026gt; pick your repo. You’ll be prompted to fill in these fields, they are probably already filled in correctly for you:\nThe next part is the advanced build settings:\nSee that pro tip about the netlify.toml? Let’s do that! You can leave these fields as is.\n Why netlify.toml? In their Build Gotchas:\n “If your build works locally, the next debugging step is to ensure the package versions we use to build match yours. You can find the settings for these in the Build Settings doc. That’s the leading cause of build failure.”\n Yes that is right- package version mismatches are the leading cause of build failure with Netlify. What does this look like for blogdown users? This means that you are running a version of Hugo locally that doesn’t match the version that Netlify is using to build your site. Most of the time, you are using a more recent version of Hugo than the one Netlify uses. This means that the files your theme relies on may be using newer Hugo functions that were introduced in later Hugo versions- functions that Netlify won’t be able to find working from an older Hugo version. You’ll get all the build errors.\nYou can check your local Hugo version by running this code in your R console:\nblogdown::hugo_version() ## [1] \u0026#39;0.57.2\u0026#39; Now, we want Netlify to use this same version of Hugo when it builds your site. You can do this two ways:\nDo this in your browser (👎) Do this in your project root directory in a netlify.toml file (👍)   Add the netlify.toml File Adding this file means that team members can see for themselves what version of Hugo you are running- if it is buried in the Netlify UI, you can’t see that information unless you sift through the public build logs (no thanks). Making the file as plain text in the root of your blogdown project directory means that:\n it is version controlled (yay!) and other people who use/learn from/contribute to your blog can actually reproduce your site with the same site configuration. Bonus: you can set the Hugo versions for branch deploys too.  Here is an example from my own netlify.toml file1:\n[build] publish = \u0026quot;public\u0026quot; command = \u0026quot;hugo\u0026quot; [context.production.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot; # if older, use format: 0.53 (no trailing zero) HUGO_ENV = \u0026quot;production\u0026quot; HUGO_ENABLEGITINFO = \u0026quot;true\u0026quot; [context.branch-deploy.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot; # if older, use format: 0.53 (no trailing zero) [context.deploy-preview.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot; You can leave off the last two chunk if you don’t want to use branch deploys or preview deploys, but I ❤️ these two Netlify features and encourage you to try them out. I’ve starting drafting individual blog posts and tutorials in branches, and then I can see them rendered and share them for feedback without asking collaborators to clone and build the repository locally. It is lovely. Every branch and pull request gets a link 🎉.\nSo add this file to your blogdown site repo and push to GitHub.\nNote that, according to the Netlify docs:\n “During a build, the following ordering determines which context covers a particular deploy: UI settings are overridden if a netlify.toml file is present in the root folder of the repo and there exists a setting for the same property/redirect/header in the toml file.”\n If you look in your site’s Netlify deploy log, you should see entries like this:\n7:47:13 PM: Found netlify.toml. Overriding site configuration 7:47:13 PM: Starting build script 7:47:13 PM: Installing dependencies 7:47:14 PM: Started restoring cached node version 7:47:17 PM: Finished restoring cached node version 7:47:18 PM: v8.15.0 is already installed. 7:47:19 PM: Now using node v8.15.0 (npm v6.4.1) 7:47:19 PM: Attempting ruby version 2.3.6, read from environment 7:47:20 PM: Using ruby version 2.3.6 7:47:20 PM: Using PHP version 5.6 7:47:20 PM: Installing Hugo 0.54.0 Success!\n  the leading zero matters for Hugo versions, so 0.53 works but .53 will not. For versions \u0026gt;= 0.54.0, the trailing zero also matters, so 0.54.0 works but 0.54 will not.↩\n   ","date":1550620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550620800,"objectID":"8a82d0bfce9f49b7c489323259c476b4","permalink":"https://nina-dl.github.io/post/2019-02-19-hugo-netlify-toml/","publishdate":"2019-02-20T00:00:00Z","relpermalink":"/post/2019-02-19-hugo-netlify-toml/","section":"post","summary":"Why you should use a netlify.toml file in your blogdown site","tags":["blogdown","netlify","hugo"],"title":"A Spoonful of Hugo: The netlify.toml File","type":"post"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":"  “Just a spoonful of Hugo helps the blog go down.” - me, only somewhat kidding\n As a happy blogdown user, a common story I hear from other #rstats users is that you try to change one little thing in Hugo, and the whole site breaks. Here be dragons for folks who aren’t web developers.\nI’m here to tell you that there are small spoonfuls of Hugo that can help you get your site UP (and even better- more efficient, more streamlined, more automated), even if you are not in the least bit interested in transitioning into a career in web development 😏.\nMy Project The education team at RStudio needs a website and we have a short wishlist:\n We want something we can maintain ourselves, We want to look consistent with other RStudio sites on the outside, and We want to be consistent on the inside so that we can get help if/when we need it.  This led me to the current tidyverse.org blogdown site. I wanted to make a copy of the site then customize for the education team, but I noticed that the source code for the site didn’t make it easy for me to copy the structure of the site and edit only the content of the site. This is one of the real strengths of Hugo, so I embarked on a learning adventure.\n   via GIPHY  As a result, I have been living and breathing Hugo lately. As in, my husband now recognizes Mike Dane’s voice. You may not have have met Mike yet, but he appears in all the video tutorials in the Hugo docs. His screencasts have been really helpful to me, like this one on templating. I’ve also spent a lot of time actually reading the docs (which are pretty good!), reading posts and answers on the Hugo discourse community site, and spelunking around inside the actual source code for two very well structured Hugo sites:\nThe actual Hugo site: https://github.com/gohugoio/hugoDocs The rOpenSci site: https://github.com/ropensci/roweb2  I’ll be using this post and other later posts to share some of the things I’ve learned about Hugo along the way. Mainly breadcrumbs to myself, but I hope these help other people too.\nFor reference, I’m using Hugo via the blogdown R package, and within the RStudio IDE. These are my blogdown and Hugo versions:\npackageVersion(\u0026quot;blogdown\u0026quot;) ## [1] \u0026#39;0.12.1\u0026#39; blogdown::hugo_version() ## [1] \u0026#39;0.55.6\u0026#39;  tl;dr: A Teaspoon of Archetypes Add custom archetypes as .md files to your project root directory (do not touch the archetypes folder in your themes/archetypes folder).  If you don’t have that as an empty folder in your project root, make one, then add your archetype files to it. If you are making a new blogdown site, I recommend using these options to keep your empty directories1:  library(blogdown) new_site(theme = \u0026quot;jpescador/hugo-future-imperfect\u0026quot;, sample = TRUE, theme_example = TRUE, empty_dirs = TRUE, # this! to_yaml = TRUE)  Figure 1: Using the RStudio Project Wizard  Use the “New Post” Addin in RStudio to create any and all new content for your site (not just posts!). Be sure to use the handy dropdown menu to select from all the possible archetypes. Also, careful about the subdirectory here- some themes use blog, others use news, articles, or posts.\n Your archetypes, while only markdown files, can include R code. When you use the Addin, be sure to choose R Markdown (.Rmd) as the format so that you can run the code.  Don’t miss this great blog post by my friend and the great educator Leo Collado-Torres on archetypes.    A Tablespoon of Archetypes One of the easiest things you can do for yourself is customize your site’s archetypes. From the Hugo docs:\n “Archetypes are templates used when creating new content.”\n Right away when I cloned the tidyverse site, I noticed that there were instructions for how to contribute a new article (or blog post) in the README.md and in a separate CONTRIBUTING.md file. Then I noticed this open GitHub issue from Mara Averick (the tidyverse developer advocate) titled “Fix README/CONTRIBUTING so there’s one source of mechanical info?”.\nI also noticed that there was no project root folder called archetypes, which is where you would store your custom site archetype files as .md files. In fact, there is no theme folder as you might expect either, which is where you could view the default theme archetypes. Let’s look at some from other Hugo themes:\nThe default Hugo theme for blogdown, Lithium, has just one archetype: default.md\n--- title: \u0026#39;\u0026#39; date: \u0026#39;\u0026#39; --- In contrast, the Hugo Academic theme has A LOT: https://github.com/gcushen/hugo-academic/tree/master/archetypes; here is the content of the one for new posts:\n+++ title = \u0026quot;{{ replace .Name \u0026quot;-\u0026quot; \u0026quot; \u0026quot; | title }}\u0026quot; subtitle = \u0026quot;\u0026quot; # Add a summary to display on homepage (optional). summary = \u0026quot;\u0026quot; date = {{ .Date }} draft = false # Authors. Comma separated list, e.g. `[\u0026quot;Bob Smith\u0026quot;, \u0026quot;David Jones\u0026quot;]`. authors = [] # Tags and categories # For example, use `tags = []` for no tags, or the form `tags = [\u0026quot;A Tag\u0026quot;, \u0026quot;Another Tag\u0026quot;]` for one or more tags. tags = [] categories = [] # Projects (optional). # Associate this post with one or more of your projects. # Simply enter your project\u0026#39;s folder or file name without extension. # E.g. `projects = [\u0026quot;deep-learning\u0026quot;]` references # `content/project/deep-learning/index.md`. # Otherwise, set `projects = []`. # projects = [\u0026quot;internal-project\u0026quot;] # Featured image # To use, add an image named `featured.jpg/png` to your page\u0026#39;s folder. [image] # Caption (optional) caption = \u0026quot;\u0026quot; # Focal point (optional) # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight focal_point = \u0026quot;\u0026quot; +++  A quick note: you may have noticed differences in both the content between these two files but also the structure. The first is a YAML file, the second is a TOML file. For blogdown users, you may want to use YAML. This is also why I recommend when you set up your site to use the to_yaml = TRUE option (in the Project Wizard from figure 1, check the “Convert all metadata to YAML” box; otherwise, the exampleSite will contain TOML instead of YAML)2.\nIf you read the original tidyverse CONTRIBUTING.md file, the instructions include a fair bit of R code that I would guess means a lot of copying and pasting into new posts. For example, the R Markdown setup chunk and the code for using usethis::use_tidy_thanks() for package releases. I studied the contributing guidelines, and parsed three different “kinds” of articles that are commonly contributed, each with a different archetype:\nThe default.md- this is just for plain old markdown posts and basically sets up the YAML of the post to be the same as it is now (currently, there is no archetype dictating the content- it is pulling from a project-level .Rprofile).\n A default-rmarkdown.md which should only be used with an R Markdown post and provides only the setup chunk at the top.\n A package-release.md which also should only be used with an R Markdown post and adds the usethis::use_tidy_thanks() code chunk (this is pseudo-code so the default chunk option is set to eval = FALSE).\n  So I drafted a pull request that adds these three archetypes to the GitHub repository for the tidyverse.org. Here is the “after” Addin view:\nHere’s hoping Hugo archetypes make some things about adding new content to your site easier. There is no Hugo involved, other than realizing that Hugo will look first in your themes/\u0026lt;THEME-NAME\u0026gt;/archetypes/ folder, then in your project root archetypes/ folder next. DO NOT TOUCH any files in your themes/ directory.3\nYou may want to set up archetypes for your blogdown site if you have a “signature” R setup chunk that loads your preferred knitr chunk options, common libraries you always load at setup like tidyverse, ggplot2 themes you prefer (theme_minimal() FTW), etc. This may be especially helpful if you have multiple team members contributing to a single site and you want their posts to have a uniform setup. Then archetypes can be a real time- and sanity-saver. Get more ideas from Leo’s blog post on archetypes. You can also make directory based archetypes if you use Hugo page bundles, which is a topic of a future post.\n  These setup options are newish to the blogdown package: https://github.com/rstudio-education/arm-workshop-rsc2019/issues/8↩\n If you end up with TOML in your content files, run this R code: hugo_convert(to = \u0026quot;YAML\u0026quot;, unsafe = TRUE)↩\n Trust me on this one- if you ever want to update your site this will make that process way harder.↩\n   ","date":1550534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550534400,"objectID":"a160260aa45ac1699baf5f119b4c4e60","permalink":"https://nina-dl.github.io/post/2019-02-19-hugo-archetypes/","publishdate":"2019-02-19T00:00:00Z","relpermalink":"/post/2019-02-19-hugo-archetypes/","section":"post","summary":"Why you should use Hugo archetypes in your blogdown site","tags":["blogdown"],"title":"A Spoonful of Hugo: Archetypes","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://nina-dl.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://nina-dl.github.io/about/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"A little more about me and my experiences","tags":null,"title":"About me","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://nina-dl.github.io/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"Get in touch","tags":null,"title":"Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://nina-dl.github.io/research/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"A little more about my research interests","tags":null,"title":"Research interest","type":"widget_page"},{"authors":["alison"],"categories":["readr","readxl","data import"],"content":"  A shorter version of this blog post now appears as an article vignette for the readxl package, thank you to Jenny Bryan for the invitation!   A problem I run up against a lot when working with other people’s data is having multiple header rows in the source data file. I like to use readr functions to read in rectangular data like .csv and .tsv files, but if you skip rows at import using the skip argument, you lose the header row as well, which usually has column names. The problem I often have is that the header row has column names that I want to keep, but I’d like to skip the second row (or more), which has some junk in it. Usually this row is some kind of data dictionary inserted between the row of column names and the actual data.\nIn this post, I’ll walk through a solution to this problem, using the readr package. You can also watch along in the video.\n  Warning!: I made a mistake when I said readr uses the first 100 rows of your data to predict column types- it uses the first 1000 rows.\n Download stickers.csv Being sticker rich This dataset is from an article published in PLOS ONE called “Being Sticker Rich: Numerical Context Influences Children’s Sharing Behavior”. In this study, children (ages 3–11) received a small (12, “sticker poor”) or large (30, “sticker rich”) number of stickers, and were then given the opportunity to share their windfall with either one or multiple anonymous recipients. This type of experimental design is a version of the Dictator Game.\nThe main research questions the authors explored were: do the number of available resources and/or the number of potential recipients alter the likelihood of a child donating and/or the amount they donate? But, in order to answer this question, we have to be able to read in the data! Luckily, these lovely developmental psychologists opted to share their data on the Harvard Dataverse as a tab-delimited file.\nIf you download the file, you can open it up in a plain text editor. You can also open it with Microsoft Excel.  Read in the file Let’s start by creating a variable called link to store the link to the data file.\n# create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot; The file has a .tab extension, so we know it is tab-delimited. This means that the right readr function for reading this file is read_tsv. Since we stored our link already as a character string, that is the only argument to the read_tsv function.\n#install.packages(\u0026quot;readr\u0026quot;) library(readr) # load the readr package stickers \u0026lt;- read_tsv(link) # spec() Now, we know the second row of data is wonky, but how can we see that in R? There are a number of ways we can go spelunking around into our data file. The easiest to print it. Since we used readr, we have a tibble, which nicely prints to screen.\nstickers # # A tibble: 402 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 [Included Sa… 1=12:1; … 1=12; 2=30 1=1 recipient;… 1=fem… NA # 2 1 1 1 1 1 36 # 3 2 1 1 1 2 36 # 4 3 1 1 1 2 36 # 5 4 1 1 1 1 36 # 6 5 1 1 1 2 36 # 7 6 1 1 1 2 36 # 8 7 2 1 2 1 36 # 9 8 2 1 2 2 36 # 10 9 3 2 1 2 36 # # … with 392 more rows, and 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, # # Agegroups \u0026lt;chr\u0026gt;, `Subject\u0026#39;sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, # # RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt; Unfortunately, dplyr::glimpse can’t help us much, because we have one variable name that is ridiculously long (absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)). We’ll fix that with dplyr::rename.\nlibrary(dplyr) glimpse(stickers) # Observations: 402 # Variables: 18 # $ SubjectNumber \u0026lt;chr\u0026gt; … # $ Condition \u0026lt;chr\u0026gt; … # $ NumberStickers \u0026lt;chr\u0026gt; … # $ NumberEnvelopes \u0026lt;chr\u0026gt; … # $ Gender \u0026lt;chr\u0026gt; … # $ Agemonths \u0026lt;dbl\u0026gt; … # $ Ageyears \u0026lt;dbl\u0026gt; … # $ Agegroups \u0026lt;chr\u0026gt; … # $ `Subject\u0026#39;sEnvelope` \u0026lt;chr\u0026gt; … # $ LeftEnvelope \u0026lt;chr\u0026gt; … # $ RightEnvelope \u0026lt;chr\u0026gt; … # $ `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt; … # $ `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt; … # $ Giveornot \u0026lt;chr\u0026gt; … # $ LargerEnvelopeabs \u0026lt;chr\u0026gt; … # $ LargeEnvelopepercent \u0026lt;chr\u0026gt; … # $ SmallerEnvelopeabs \u0026lt;chr\u0026gt; … # $ SmallEnvelopepercent \u0026lt;chr\u0026gt; … More options:\nhead(stickers) # # A tibble: 6 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 [Included Sa… 1=12:1; … 1=12; 2=30 1=1 recipient;… 1=fem… NA # 2 1 1 1 1 1 36 # 3 2 1 1 1 2 36 # 4 3 1 1 1 2 36 # 5 4 1 1 1 1 36 # 6 5 1 1 1 2 36 # # … with 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, Agegroups \u0026lt;chr\u0026gt;, # # `Subject\u0026#39;sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt; tail(stickers) # # A tibble: 6 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 396 1 1 1 2 136 # 2 397 4 2 2 1 136 # 3 398 1 1 1 1 137 # 4 399 1 1 1 2 137 # 5 400 4 2 2 2 139 # 6 401 3 2 1 1 143 # # … with 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, Agegroups \u0026lt;chr\u0026gt;, # # `Subject\u0026#39;sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt; names(stickers) # [1] \u0026quot;SubjectNumber\u0026quot; # [2] \u0026quot;Condition\u0026quot; # [3] \u0026quot;NumberStickers\u0026quot; # [4] \u0026quot;NumberEnvelopes\u0026quot; # [5] \u0026quot;Gender\u0026quot; # [6] \u0026quot;Agemonths\u0026quot; # [7] \u0026quot;Ageyears\u0026quot; # [8] \u0026quot;Agegroups\u0026quot; # [9] \u0026quot;Subject\u0026#39;sEnvelope\u0026quot; # [10] \u0026quot;LeftEnvelope\u0026quot; # [11] \u0026quot;RightEnvelope\u0026quot; # [12] \u0026quot;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026quot; # [13] \u0026quot;PercentGiven(Outof100percent)\u0026quot; # [14] \u0026quot;Giveornot\u0026quot; # [15] \u0026quot;LargerEnvelopeabs\u0026quot; # [16] \u0026quot;LargeEnvelopepercent\u0026quot; # [17] \u0026quot;SmallerEnvelopeabs\u0026quot; # [18] \u0026quot;SmallEnvelopepercent\u0026quot; # View() Now we are ready to diagnose the problem!\nProblem: the first row is not really data. It is metadata about the variables, and it is screwing up readr’s ability to predict our column types.\nSolution: we’ll use readr and the read_tsv() function to read in the data twice. In Step 1, we’ll create a character vector of the column names only. In Step 2, we’ll read in the actual data and skip the multiple header rows at the top. When we do this, we lose the column names, so we use the character vector of column names we created in Step 1 instead.\n Read in the file (again) Step 1 Goal: we want to read in the first row only and save it as a character vector called sticker_names. This row contains the correct column names that we’ll need in Step 2.\nsticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = \u0026#39;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026#39;) %\u0026gt;% names() sticker_names # [1] \u0026quot;SubjectNumber\u0026quot; \u0026quot;Condition\u0026quot; # [3] \u0026quot;NumberStickers\u0026quot; \u0026quot;NumberEnvelopes\u0026quot; # [5] \u0026quot;Gender\u0026quot; \u0026quot;Agemonths\u0026quot; # [7] \u0026quot;Ageyears\u0026quot; \u0026quot;Agegroups\u0026quot; # [9] \u0026quot;Subject\u0026#39;sEnvelope\u0026quot; \u0026quot;LeftEnvelope\u0026quot; # [11] \u0026quot;RightEnvelope\u0026quot; \u0026quot;stickersgiven\u0026quot; # [13] \u0026quot;PercentGiven(Outof100percent)\u0026quot; \u0026quot;Giveornot\u0026quot; # [15] \u0026quot;LargerEnvelopeabs\u0026quot; \u0026quot;LargeEnvelopepercent\u0026quot; # [17] \u0026quot;SmallerEnvelopeabs\u0026quot; \u0026quot;SmallEnvelopepercent\u0026quot; glimpse(sticker_names) # chr [1:18] \u0026quot;SubjectNumber\u0026quot; \u0026quot;Condition\u0026quot; \u0026quot;NumberStickers\u0026quot; ...  Step 2 Goal: we want to read in all the rows except for the first two rows, which contained the variable names and variable descriptions. We want to save this as stickers, and set the column names to the sticker_names object we created in Step 1.\nstickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names) glimpse(stickers) # Observations: 401 # Variables: 18 # $ SubjectNumber \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1… # $ Condition \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3,… # $ NumberStickers \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,… # $ NumberEnvelopes \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,… # $ Gender \u0026lt;dbl\u0026gt; 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2,… # $ Agemonths \u0026lt;dbl\u0026gt; 36, 36, 36, 36, 36, 36, 36, 36, … # $ Ageyears \u0026lt;dbl\u0026gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,… # $ Agegroups \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… # $ `Subject\u0026#39;sEnvelope` \u0026lt;dbl\u0026gt; 7, 12, 4, 7, 12, 8, 8, 11, 26, 3… # $ LeftEnvelope \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 2, 1, 4, 0, 18… # $ RightEnvelope \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA… # $ stickersgiven \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 4, 1, 4, 0, 18… # $ `PercentGiven(Outof100percent)` \u0026lt;dbl\u0026gt; 0.42, 0.00, 0.67, 0.42, 0.00, 0.… # $ Giveornot \u0026lt;dbl\u0026gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,… # $ LargerEnvelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 1, NA… # $ LargeEnvelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.500000… # $ SmallerEnvelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA… # $ SmallEnvelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.500000…   Fin! All together now: the final solution!\n# load packages library(readr) library(dplyr) # create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot; # read in column names only sticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = \u0026#39;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026#39;) %\u0026gt;% names() # read in data, set column names stickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names)  Addendum For good measure, I would add a final step to everything above and use janitor::clean_names() to put all the variable names into snake case. So my final final solution is here:\n# load packages library(readr) library(dplyr) library(janitor) # create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot; # read in column names only sticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = \u0026#39;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026#39;) %\u0026gt;% names() # read in data, set column names stickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names) %\u0026gt;% clean_names() stickers # # A tibble: 401 x 18 # subject_number condition number_stickers number_envelopes gender # \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; # 1 1 1 1 1 1 # 2 2 1 1 1 2 # 3 3 1 1 1 2 # 4 4 1 1 1 1 # 5 5 1 1 1 2 # 6 6 1 1 1 2 # 7 7 2 1 2 1 # 8 8 2 1 2 2 # 9 9 3 2 1 2 # 10 10 3 2 1 2 # # … with 391 more rows, and 13 more variables: agemonths \u0026lt;dbl\u0026gt;, # # ageyears \u0026lt;dbl\u0026gt;, agegroups \u0026lt;dbl\u0026gt;, subjects_envelope \u0026lt;dbl\u0026gt;, # # left_envelope \u0026lt;dbl\u0026gt;, right_envelope \u0026lt;dbl\u0026gt;, stickersgiven \u0026lt;dbl\u0026gt;, # # percent_given_outof100percent \u0026lt;dbl\u0026gt;, giveornot \u0026lt;dbl\u0026gt;, # # larger_envelopeabs \u0026lt;dbl\u0026gt;, large_envelopepercent \u0026lt;dbl\u0026gt;, # # smaller_envelopeabs \u0026lt;dbl\u0026gt;, small_envelopepercent \u0026lt;dbl\u0026gt; glimpse(stickers) # Observations: 401 # Variables: 18 # $ subject_number \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,… # $ condition \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3… # $ number_stickers \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2… # $ number_envelopes \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1… # $ gender \u0026lt;dbl\u0026gt; 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1… # $ agemonths \u0026lt;dbl\u0026gt; 36, 36, 36, 36, 36, 36, 36, 36, 36… # $ ageyears \u0026lt;dbl\u0026gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3… # $ agegroups \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… # $ subjects_envelope \u0026lt;dbl\u0026gt; 7, 12, 4, 7, 12, 8, 8, 11, 26, 30,… # $ left_envelope \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 2, 1, 4, 0, 18, … # $ right_envelope \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, … # $ stickersgiven \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 4, 1, 4, 0, 18, … # $ percent_given_outof100percent \u0026lt;dbl\u0026gt; 0.42, 0.00, 0.67, 0.42, 0.00, 0.33… # $ giveornot \u0026lt;dbl\u0026gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1… # $ larger_envelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 1, NA, … # $ large_envelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000,… # $ smaller_envelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, … # $ small_envelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000,…  Bonus data dictionary As an extra bonus, when you do have extra header rows, you can create a data dictionary using the gather() function from the tidyr package.\nlibrary(tidyr) stickers_dict \u0026lt;- read_tsv(link, n_max = 1) %\u0026gt;% rename(stickersgiven = \u0026#39;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026#39;) %\u0026gt;% clean_names() %\u0026gt;% gather(variable_name, variable_description) stickers_dict # # A tibble: 18 x 2 # variable_name variable_description # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; # 1 subject_number [Included Sample Only] # 2 condition 1=12:1; 2=12:2, 3=30:1, 4=30:2 # 3 number_stickers 1=12; 2=30 # 4 number_envelopes 1=1 recipient; 2=2 recipients # 5 gender 1=female; 2=male # 6 agemonths \u0026lt;NA\u0026gt; # 7 ageyears \u0026lt;NA\u0026gt; # 8 agegroups 1=3-4yrs; 2=5-6yrs; 3=7-8yrs; 4=9-11yrs # 9 subjects_envelope How many stickers did the child keep for themse… # 10 left_envelope 1 recipient conditions: How many stickers the s… # 11 right_envelope 1 recipient conditions: N/A; 2 recipient condit… # 12 stickersgiven Regardless of condition, the number of stickers… # 13 percent_given_outof100… Regardless of condition, the proportion of stic… # 14 giveornot 1=Donated 1 or more stickers to the recipient(s… # 15 larger_envelopeabs Raw number of stickers (out of 30: Condition 2 … # 16 large_envelopepercent Proportion of stickers (out of 100%; Condition … # 17 smaller_envelopeabs Raw number of stickers (out of 30: Condition 2 … # 18 small_envelopepercent Proportion of stickers (out of 100%; Condition …  Useful resources  Great blog post from Lisa DeBruine using readxl to read in data with multiple header rows (including those with merged cells!): https://debruine.github.io/multirow_headers.html This GitHub issue with Hadley’s response that solved all my problems: https://github.com/tidyverse/readr/issues/179 My original tweet when I discovered this trick!  Neat #rstats #readr #tidyverse solution to read data when 1st row is header + 2nd row is junk, thanks @hadleywickham https://t.co/5TuH7vNaID pic.twitter.com/woZ3HuECge\n\u0026mdash; Alison Presmanes Hill (@apreshill) September 4, 2017   ","date":1531008000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531008000,"objectID":"c18d02feb96be2ee747ed7aa57c7bcc4","permalink":"https://nina-dl.github.io/post/2018-02-23-read-multiple-header-rows/","publishdate":"2018-07-08T00:00:00Z","relpermalink":"/post/2018-02-23-read-multiple-header-rows/","section":"post","summary":"Using the readr package to sidestep a common problem","tags":null,"title":"Read Data with Multiple Header Rows into R","type":"post"},{"authors":["alison"],"categories":["rladies","xaringan"],"content":" So, you are doing an R-Ladies presentation…that’s awesome!\nThe short version I made an R-Ladies theme for xaringan slides. My original tweet about it:\nif you want to use @xieyihui\u0026#39;s awesome #xaringan package for #rstats slides but want more #Rladies flavor, there is now a built-in theme for that (with code highlighting)! Thanks to the awesome @RLadiesGlobal starter kit. Update the CSS in your YAML to use 🧙🏽‍♀️🧞‍♀️ pic.twitter.com/YnlGSVAMsl\n\u0026mdash; Alison Presmanes Hill (@apreshill) November 29, 2017  The way to use the theme is to update the YAML like so:\noutput: xaringan::moon_reader: css: [\u0026quot;default\u0026quot;, \u0026quot;rladies\u0026quot;, \u0026quot;rladies-fonts\u0026quot;] Make sure your version of xaringan is up-to-date.\nBelow is a demo slide deck using the theme.\n (view the source .Rmd on GitHub)\n The longer story I recommend Yihui’s xaringan package for slides. This is an R package, available through GitHub, for creating slideshows with remark.js through R Markdown. This means that you can:\n write all your slides in Markdown text include chunks of R code and rendered output like plots, results, tables, etc. in your slides use git for version control and share your GitHub repository  This makes xaringan ideal for an R-Ladies presentation!1\nTo use the package, you’ll need the devtools package installed so that you can use the install_github function. Then do:\ndevtools::install_github(\u0026#39;yihui/xaringan\u0026#39;) As Yihui points out in the documentation, if you use RStudio, you can use the menu to navigate to File -\u0026gt; New File -\u0026gt; R Markdown -\u0026gt; From Template -\u0026gt; Ninja Presentation, and you will see an R Markdown example.\nI first used xaringan a few months ago. I was working with Yihui on the blogdown book, and had signed up to lead a workshop for the Portland R User group. Obviously, such a workshop could not have powerpoint slides, so it seemed like the perfect time to learn xaringan.\nFor my workshop, I made a simple website for the newly founded R-Ladies PDX using blogdown (Thanks to Augustina and Deeksha, our fearless organizers). So naturally, my slides needed more purple.\nLuckily, the R-Ladies run a tight ship- they have a starter kit on GitHub that details all the pretty purples they like.\n About a month after I did the R-Ladies blogdown workshop, I saw this blog post by Yihui:\n First, I thought this was such a cool idea and I hope more people make and submit themes. Then I realized, I had already made a theme! I submitted a pull request2, Yihui helped me make some edits to the CSS files to make them more parsimonious with the default theme, I electronically signed a contributor agreement, and now the theme is there for you all to enjoy and use! You use the theme by editing the YAML:\noutput: xaringan::moon_reader: css: [\u0026quot;default\u0026quot;, \u0026quot;rladies\u0026quot;, \u0026quot;rladies-fonts\u0026quot;] If you use the theme and you are on twitter, I’d love to see it- please mention me on twitter!\nExamples!\n My blogdown workshop slides: “Up and running with blogdown” (view the source .Rmd on GitHub)    Jessica Minnier’s slides for “Building Shiny Apps: With Great Power Comes Great Responsibility”     If you are new to xaringan, don’t miss the wiki!↩\n Yihui’s technical instructions for contributors section of that blog post has been revised and is very detailed↩\n   ","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513555200,"objectID":"4bae6dbc2d30b9c31fdd99c5dcdd6a81","permalink":"https://nina-dl.github.io/post/2017-12-18-r-ladies-presentation-ninja/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/post/2017-12-18-r-ladies-presentation-ninja/","section":"post","summary":"A guide to using the R-Ladies xaringan slide theme","tags":["xaringan"],"title":"R-Ladies Presentation Ninja","type":"post"},{"authors":["alison"],"categories":["blogdown","hugo","netlify"],"content":"  1 Read up on blogdown 2 Caveats, disclaimers, etc. 3 In GitHub 4 In terminal 5 In RStudio 6 Build your site in RStudio 7 Deploy in Netlify 8 Going further   1 Read up on blogdown Before you start, I recommend reading the following:\n blogdown: Creating Websites with R Markdown by Yihui Xie and Amber Thomas Making a Website Using blogdown, Hugo, and GitHub pages also by Amber Thomas  I also found this comment by Eric Nantz, the creator of the R-Podcast, in the rbind/support issues section on GitHub to be helpful:\n https://github.com/rbind/support/issues/12   2 Caveats, disclaimers, etc. Even with all the great resources I listed above, getting myself up and running took a few tries, so in this post I’m passing along what ended up working for me. Everyone’s mileage may vary, though, depending on your operating system and your approach. About me: I am a macOS user, and I use R, RStudio, Git (usually via GitLab, sometimes via GitHub), and terminal regularly, so I’m assuming familiarity here with all of these. If that is not you, here are some places to get started:\n For Git: Happy Git with R by Jenny Bryan et al. For RStudio: DataCamp’s Working with the RStudio IDE (free) by Garrett Grolemund For Terminal: The Command Line Murder Mystery by Noah Veltman, and The UNIX Workbench by Sean Kross  I also have Xcode and Homebrew installed- you will probably need these to download Hugo. If you don’t have either but are on a mac, this link may help:\n How to install Xcode, Homebrew, Git, RVM, Ruby \u0026amp; Rails on Mac OS X  Finally, I did not want to learn more about a lot of things! For instance, the nitty gritty of static site generators and how domain names work. I am a new mom, and just in the process of writing all this up, I filled up my tea mug twice with ice cold water, and filled my water bottle with scalding hot water. So, where offered, I followed the advice of Yihui and Amber. For example:\n “Considering the cost and friendliness to beginners, we currently recommend Netlify.” Sold. “If you are not familiar with domain names or do not want to learn more about them, an option for your consideration is a free subdomain *.rbind.io offered by RStudio, Inc.”. Done.   3 In GitHub  Go online to your GitHub account, and create a new repository (check to initialize with a README but don’t add .gitignore- this will be taken care of later). For naming your repo, consider your future deployment plan:\n If you are going to use Netlify to host the site, you can name this repository anything you want!  You can see some of the repo names used by members of the rbind organization here.    If you want to host your site as a GitHub Page, you should name your repository yourgithubusername.github.io (so mine would have been apreshill.github.io). If you are going this route, I suggest you follow Amber’s instructions instead of mine!   Screenshot above: Creating a new repository in GitHub\n Go to the main page of your new repository, and under the repository name, click the green Clone or download button.\n In the Clone with HTTPs section, click on the clipboard icon to copy the clone URL for your new repository. You’ll paste this text into terminal in the next section.\n   4 In terminal  Now you will clone your remote repository and create a local copy on your computer so you can sync between the two locations (using terminal or your alternative command line tool for a Windows machine).\nUse cd to navigate into the directory where you want your repo to be\n Once there, type: git clone [paste]. So my command looked like this:\n  git clone https://github.com/apreshill/apreshill.git And this is what printed to my terminal window:\nCloning into \u0026#39;apreshill\u0026#39;... remote: Counting objects: 3, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. Checking connectivity... done. Close terminal, you are done in there.   5 In RStudio  Install blogdown from your RStudio console. If you already have devtools installed like I did, you can just use the second line below:  if (!requireNamespace(\u0026quot;devtools\u0026quot;)) install.packages(\u0026quot;devtools\u0026quot;) devtools::install_github(\u0026quot;rstudio/blogdown\u0026quot;) Install Hugo using the blogdown package helper function:  blogdown::install_hugo() # or library(blogdown) install_hugo()  This is where my instructions diverge from Ed’s- he states that blogdown won’t create a website in your root folder because the README.md file is already there. I didn’t find that to be the case- I tested this with a new site as well. If one way doesn’t work for you, try the other!   Use the top menu buttons in RStudio to select File -\u0026gt; New Project -\u0026gt; Existing Directory, then browse to the directory on your computer where your GitHub repo is and click on the Create Project button.  Screenshot above: Creating a new project in an existing directory in RStudio\n Now you should be “in” your project in RStudio. If you are using git for version control, edit your *gitignore file. This file should be viewable in your file viewer pane in RStudio. Below is what it should look like: the first four lines will automatically be in this file if you have set up your RStudio Project, but if you plan to use Netlify to deploy, you need to add the public/ line (read about here.)  .Rproj.user .Rhistory .RData .Ruserdata blogdown .DS_Store # if a windows user, Thumbs.db instead public/ # if using Netlify  6 Build your site in RStudio  Now you can finally build your site using the blogdown::new_site() function. But first you should at least think about themes…\n6.1 Picking a theme There are over 90 Hugo themes. So I went back to the blogdown book. Thankfully, Yihui and Amber offer “to save you some time, we list a few themes below that match our taste…”. Huzzah- I went with hugo-academic! Whatever theme you choose, you’ll need to pick one of 3 ways to make your new site:\nIf you are happy with the default theme, which is the lithium theme, you can use:  blogdown::new_site() # default theme is lithium If you want a theme other than the default, you can specify the theme at the same time as you call the new_site function:  # for example, create a new site with the academic theme blogdown::new_site(theme = \u0026quot;gcushen/hugo-academic\u0026quot;, theme_example = TRUE) If instead you want to add the theme later (like I did, because I didn’t see the above example until it was too late!), you can do this:  library(blogdown) new_site() # default theme is lithium # need to stop serving so can use the console again install_theme(\u0026quot;gcushen/hugo-academic\u0026quot;, theme_example = TRUE, update_config = TRUE)  Now is a good time to re-read about blogdown::serve_site() and how LiveReload works (and how it blocks your R console by default)   I recommend setting theme_example = TRUE- some themes won’t provide an example site, but the academic theme did and I found it helpful to see. You can always delete the example content.\n 6.2 Update project options In your project in RStudio, go to the top menu bar of RStudio and select Tools -\u0026gt; Project Options and update following Yihui and Amber’s instructions.\n 6.3 Edit your configurations Relevant reading:\n blogdown book chapter on configuration Additional detail from Amber You can also view my config.toml file  Now, edit the baseurl in your config.toml file. The URL should always end with a / trailing slash. At this point, you probably haven’t deployed your site yet, so to view it locally you can use the Serve Site add-in, or run the blogdown::serve_site function. Both of these baseurls worked for me when viewing locally:\nbaseurl = \u0026quot;https://example.com/\u0026quot; baseurl = \u0026quot;/\u0026quot;  Make sure that the baseurl = listed ends with a trailing slash /!   Go ahead and edit all the other elements in the config.toml file now as you please- this is how you personalize your site!\n 6.4 Addins \u0026amp; workflow Relevant reading:\n blogdown book chapter on the RStudio IDE  Addins: use them- you won’t need the blogdown library loaded in the console if you use the Addins. My workflow in RStudio at this point (again, just viewing locally because we haven’t deployed yet) works best like this:\nOpen the RStudio project for the site Use the Serve Site add-in (only once due to the magic of LiveReload) View site in the RStudio viewer pane, and open in a new browser window while I work Select existing files to edit using the file pane in RStudio After making changes, click the save button (don’t knit!)- the console will reload, the viewer pane will update, and if you hit refresh in the browser your local view will also be updated When happy with changes, add/commit/push changes to GitHub  Having blogdown::serve_site running locally with LiveReload is especially useful as you can immediately see if you have totally screwed up. For example, in editing my about.md file, this error popped up in my console after making a change and I was able to fix the error right away:\nStarted building sites ... ERROR 2017/06/08 16:22:34 failed to parse page metadata for home/about.md: (18, 6): missing comma Error: Error building site: Errors reading pages: Error: failed to parse page metadata for home/about.md: (18, 6): missing comma for about.md The above workflow is only for editing existing files or posts, but not for creating new posts. For that, read on…\n 6.5 Posting Relevant reading:\n blogdown book chapter on RStudio IDE blogdown book chapter on output formats: on .md versus .Rmd posts Additional detail from Amber on adding a blog post  Bottom line:\nUse the New Post addin. But, you need the console to do this, so you have to stop blogdown::serve_site by clicking on the red Stop button first. The Addin is a Shiny interface that runs this code in your console: blogdown:::new_post_addin(). So, your console needs to be unblocked for it to run. You also need to be “in” your RStudio project or it won’t work.\n6.5.1 Draft posts Relevant reading:\n blogdown book chapter on building a website for local preview  Whether you do a markdown or R Markdown post (see below), you should know that in the YAML front matter of your new file, you can add draft: TRUE and you will be able to preview your post using blogdown::serve_site(), but conveniently your post will not show up on your deployed site until you set it to false. Because this is a function built into Hugo, all posts (draft or not) will still end up in your GitHub repo though.\n 6.5.2 New markdown posts Pick one of 2 methods:\nUse the New Post addin and with the radio button at the bottom select Format: Markdown (recommended) Use the console to author a new .md post:  blogdown::new_post() blogdown::new_post(ext = \u0026#39;.md\u0026#39;) # md is the default! Here are the ?new_post arguments:\nnew_post(title, kind = \u0026quot;\u0026quot;, open = interactive(), author = getOption(\u0026quot;blogdown.author\u0026quot;), categories = NULL, tags = NULL, date = Sys.Date(), file = NULL, slug = NULL, title_case = getOption(\u0026quot;blogdown.title_case\u0026quot;), subdir = getOption(\u0026quot;blogdown.subdir\u0026quot;, \u0026quot;post\u0026quot;), ext = getOption(\u0026quot;blogdown.ext\u0026quot;, \u0026quot;.md\u0026quot;))  Remember to use the Serve Site addin again so that you can immediately view your changes with every save using LiveReload.    6.5.3 New R Markdown (.Rmd) posts Again, you have your choice of one of 2 methods:\nUse the New Post addin and with the radio button at the bottom select Format: R Markdown (.Rmd) (recommended) Use the console to author a new .Rmd post:  blogdown::new_post(ext = \u0026#39;.Rmd\u0026#39;) # md is the default! After you edit your .Rmd post, in addition to saving the changes in your .Rmd file, you must use blogdown::serve_site- this is how the output html file needs to be generated.\n Do not knit your .Rmd posts- use blogdown::serve_site instead. If you happen to hit the knit button, just Serve Site again to rewrite the .html file.   Ultimately, your YAML front matter looks something like this; note that some but not all features of rmarkdown::html_document are supported in blogdown:\n--- title: \u0026quot;My Awesome Post\u0026quot; author: \u0026quot;John Doe\u0026quot; date: \u0026quot;2017-02-14\u0026quot; output: blogdown::html_page: toc: true toc_depth: 1 number_sections: true fig_width: 6 ---  Remember to use the Serve Site addin again so that you can immediately view your changes with every save using LiveReload and your .html file is properly output.    6.5.4 Adding images to a post If you want to include an image that is not a figure created from an R chunk, the recommended method is to:\nAdd the image to your /static/img/ folder, then Reference the image using the relative file path as follows:  ![my-image](/img/my-image.png)    7 Deploy in Netlify  Deploying in Netlify through GitHub is smooth. Yihui and Amber give some beginner instructions, but Netlify is so easy, I recommend that you skip dragging your public folder in and instead automate the process through GitHub.\nWhen you are ready to deploy, commit your changes and push to GitHub, then go online to Netlify. Click on the Sign Up button and sign up using your existing GitHub account (no need to create another account) Log in, and select: New site from Git -\u0026gt; Continuous Deployment: GitHub. From there, Netlify will allow you to select from your existing GitHub repositories. You’ll pick the repo you’ve been working from with blogdown, then you’ll configure your build. This involves specifying two important things: the build command and the publish directory (this should be public).\n More about the build command from Netlify: “For Hugo hosting, hugo will build and deploy with the version 0.17 of hugo. You can specify a specific hugo release like this: hugo_0.15. Currently 0.13, 0.14, 0.15, 0.16, 0.17, 0.18 and 0.19 are supported. For version 0.20 and above, you’ll need to create a Build environment variable called HUGO_VERSION and set it to the version of your choice.” I opted for the former, and specified hugo_0.19.   You can check your hugo version in terminal using the command hugo version. This is what my output looked like, so I could run version 0.20 if I wanted to through Netlify, but I went with 0.19 and it works just fine.\n$ hugo version Hugo Static Site Generator v0.20.7 darwin/amd64 BuildDate: 2017-05-08T18:37:40-07:00 Screenshot above: Basic build settings in Netlify\n Netlify will deploy your site and assign you a random subdomain name of the form random-word-12345.netlify.com. Mine was particularly unfortunate, with the random word garbage-collector-janice. You should know that you can change this; I changed mine to apreshill.netlify.com.\n Anytime you change your subdomain name, you need to update the baseurl in your config.toml file (so I changed mine to baseurl = “https://apreshill.netlify.com/”).   At this point, you should be up and running with blogdown, GitHub, and Netlify, but here are some ideas if you want to go further…\n 8 Going further 8.1 Custom CSS I like to tinker with default theme settings like colors and fonts. Every Hugo theme is structured a little differently, but if you are interested, you can check out my custom css to see how I customized the academic theme, which provides a way to link to a custom CSS file in the config.toml file:\n # Link custom CSS and JS assets # (relative to /static/css and /static/js respectively) custom_css = [\u0026quot;blue.css\u0026quot;]  8.2 Formspree I used Formspree to make a contact form, which is an online service (managed on GitHub) that allows you to add an HTML form to your static site. No registration, just use the form and confirm your email address once. I added the following code into my contact widget:\n\u0026lt;form action=\u0026quot;https://formspree.io/your@email.com\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;name\u0026quot;\u0026gt;Your name: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; required=\u0026quot;required\u0026quot; placeholder=\u0026quot;here\u0026quot;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;label for=\u0026quot;email\u0026quot;\u0026gt;Your email: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;email\u0026quot; name=\u0026quot;_replyto\u0026quot; required=\u0026quot;required\u0026quot; placeholder=\u0026quot;here\u0026quot;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;label for=\u0026quot;message\u0026quot;\u0026gt;Your message:\u0026lt;/label\u0026gt;\u0026lt;br\u0026gt; \u0026lt;textarea rows=\u0026quot;4\u0026quot; name=\u0026quot;message\u0026quot; id=\u0026quot;message\u0026quot; required=\u0026quot;required\u0026quot; class=\u0026quot;form-control\u0026quot; placeholder=\u0026quot;I can\u0026#39;t wait to read this!\u0026quot;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;_next\u0026quot; value=\u0026quot;/html/thanks.html\u0026quot; /\u0026gt; \u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Send\u0026quot; name=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary btn-outline\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;_subject\u0026quot; value=\u0026quot;Website message\u0026quot; /\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;_gotcha\u0026quot; style=\u0026quot;display:none\u0026quot; /\u0026gt; \u0026lt;/form\u0026gt;  8.3 *.rbind.io domain names You may want a different domain name than the one provided by Netlify. I opted for a free subdomain *.rbind.io offered by RStudio. To do the same, head over to the rbind/support GitHub page and open a new issue. All you need to do is let them know what your Netlify subdomain name is (*.netlify.com), and what you want your subdomain name to be (*.rbind.io). The awesome rbind support team will help you take it from there!\n Again, you will need to update the baseurl in your config.toml file to reflect your new rbind subdomain name (so mine is baseurl = “https://alison.rbind.io/”).     8.4 Have fun! Lastly, don’t forget to just have fun with it. Happy blogdowning!\n  via GIPHY   ","date":1497225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497225600,"objectID":"dbf96d61412119467fb5db386d4f4407","permalink":"https://nina-dl.github.io/post/2017-06-12-up-and-running-with-blogdown/","publishdate":"2017-06-12T00:00:00Z","relpermalink":"/post/2017-06-12-up-and-running-with-blogdown/","section":"post","summary":"A guide to getting up and running with blogdown, GitHub, and Netlify","tags":["blogdown"],"title":"Up \u0026 Running with blogdown","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://nina-dl.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://nina-dl.github.io/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Nina Deliu","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://nina-dl.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Nina Deliu","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://nina-dl.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]