<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tidymodels | Nina Deliu</title>
    <link>/tags/tidymodels/</link>
      <atom:link href="/tags/tidymodels/index.xml" rel="self" type="application/rss+xml" />
    <description>tidymodels</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>¬© Nina Deliu, 2020</copyright><lastBuildDate>Thu, 27 Feb 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar.jpg</url>
      <title>tidymodels</title>
      <link>/tags/tidymodels/</link>
    </image>
    
    <item>
      <title>Take a Sad Script &amp; Make it Better: Tidymodels Edition</title>
      <link>/post/2020-02-27-better-tidymodels/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-02-27-better-tidymodels/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-sad-script-symphony&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; A sad script symphony üéª üé∑ üéπ&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#packages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Packages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#penguins&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;4&lt;/span&gt; Penguins&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidymodels-101&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;5&lt;/span&gt; tidymodels 101&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hey-jude-dont-make-it-sad&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;6&lt;/span&gt; Hey Jude, don‚Äôt make it sad üé∂&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#make-it-better&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;7&lt;/span&gt; Make it better&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;A few years ago, I did a talk called &lt;a href=&#34;/talk/2018-ohsu-sad-plot-better/&#34;&gt;‚ÄúTake a Sad Plot &amp;amp; Make it Better,‚Äù&lt;/a&gt; where I showed how I took a single sad plot and tried to make it better. The process of making that plot better taught me a lot about data visualization, and about the &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2 package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fast-forward to 2019 when I started learning &lt;a href=&#34;https://github.com/tidymodels/&#34;&gt;tidymodels&lt;/a&gt;, and I have accumulated some pretty sad predictive modeling scripts! And my sad plots are not so lonely anymore. Specifically, my old scripts for doing cross-validation with tidymodels are particularly sad. But, I‚Äôve been able to make them better (one might even call them happy), primarily due to changes in the &lt;a href=&#34;https://tidymodels.github.io/tune/&#34;&gt;tune package&lt;/a&gt; and the addition of the &lt;code&gt;fit_resamples()&lt;/code&gt; function. The process of making these scripts better taught me a lot about predictive modeling, and about the (evolving) tidymodels ecosystem. So, why write a blog post with outdated code?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;I want to remember &lt;em&gt;that&lt;/em&gt; I did this ‚Äúby hand.‚Äù&lt;/li&gt;
&lt;li&gt;I want to remember &lt;em&gt;how&lt;/em&gt; I did this ‚Äúby hand.‚Äù The code still works, even if there is now a happier path to doing the same thing.&lt;/li&gt;
&lt;li&gt;I want to share cute penguin art and gifs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let‚Äôs start with some &lt;a href=&#34;http://www.greenhumour.com/2018/04/penguins-of-world.html&#34;&gt;cute penguin art&lt;/a&gt; by Rohan Chakravarty‚Ä¶&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.greenhumour.com/2018/04/penguins-of-world.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;penguins-of-the-world.JPG&#34; width=&#34;270&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;My objective here is &lt;strong&gt;not&lt;/strong&gt; to provide an introduction to using tidymodels, cross-validation, or to machine learning. If that is what you came for, check out the project button at the top of this post for my workshop materials for learners, and my &lt;a href=&#34;https://education.rstudio.com/blog/2020/02/conf20-intro-ml/&#34;&gt;associated blog post&lt;/a&gt; on the RStudio education site.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Bottom line:&lt;/strong&gt; If you are stumbling upon this blog post in the year 2020 or beyond, know that there is a better way!
  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;div id=&#34;a-sad-script-symphony&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; A sad script symphony üéª üé∑ üéπ&lt;/h1&gt;
&lt;p&gt;I‚Äôm not the first person to write sad tidymodels scripts- there are many out in the wild. Here were the blog posts that I found most helpful when trying to solve this particular coding conundrum:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c&#34;&gt;Modelling with Tidymodels and Parsnip: A Tidy Approach to a Classification Problem&lt;/a&gt; by Diego Usai&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.brodrigues.co/blog/2018-11-25-tidy_cv/&#34;&gt;A tutorial on tidy cross-validation with R&lt;/a&gt; by Bruno Rodrigues&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.benjaminsorensen.me/post/modeling-with-parsnip-and-tidymodels/&#34;&gt;Modeling with parsnip and tidymodels&lt;/a&gt; by Benjamin Sorensen&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Packages&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(tidymodels)
library(rpart)  # for decision tree
library(ranger) # for random forest&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; Data&lt;/h1&gt;
&lt;p&gt;I‚Äôm going to use data that Allison Horst helped me source on penguins from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Palmer_Station&#34;&gt;Palmer Station&lt;/a&gt; (Antarctica) &lt;a href=&#34;https://lternet.edu/&#34;&gt;Long Term Ecological Research Network&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‚Äúsooo now I‚Äôm just looking at penguin pictures‚Äù
- &lt;a href=&#34;https://twitter.com/allison_horst?lang=en&#34;&gt;Allison Horst&lt;/a&gt; after slacking me this penguin data&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here are the three dataset sources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adelie penguins:
&lt;a href=&#34;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.219.3&#34; class=&#34;uri&#34;&gt;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.219.3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chinstrap penguins:
&lt;a href=&#34;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.220.3&#34; class=&#34;uri&#34;&gt;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.220.3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gentoo penguins:
&lt;a href=&#34;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.221.2&#34; class=&#34;uri&#34;&gt;https://portal.lternet.edu/nis/mapbrowse?packageid=knb-lter-pal.221.2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I downloaded and imported these three datasets using R, then did some very light data wrangling and merged them into one called &lt;a href=&#34;data/penguins.csv&#34;&gt;&lt;code&gt;penguins&lt;/code&gt;&lt;/a&gt;, which I‚Äôll use now:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins &amp;lt;- 
  read_csv(
    here::here(&amp;quot;content/post/2020-02-27-better-tidymodels/data/penguins.csv&amp;quot;)) %&amp;gt;% 
  mutate_if(is.character, as.factor)
#&amp;gt; Parsed with column specification:
#&amp;gt; cols(
#&amp;gt;   species = col_character(),
#&amp;gt;   culmen_length_mm = col_double(),
#&amp;gt;   culmen_depth_mm = col_double(),
#&amp;gt;   flipper_length_mm = col_double(),
#&amp;gt;   body_mass_g = col_double(),
#&amp;gt;   sex = col_character()
#&amp;gt; )

glimpse(penguins)
#&amp;gt; Observations: 333
#&amp;gt; Variables: 6
#&amp;gt; $ species           &amp;lt;fct&amp;gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade‚Ä¶
#&amp;gt; $ culmen_length_mm  &amp;lt;dbl&amp;gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.‚Ä¶
#&amp;gt; $ culmen_depth_mm   &amp;lt;dbl&amp;gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.‚Ä¶
#&amp;gt; $ flipper_length_mm &amp;lt;dbl&amp;gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 1‚Ä¶
#&amp;gt; $ body_mass_g       &amp;lt;dbl&amp;gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 380‚Ä¶
#&amp;gt; $ sex               &amp;lt;fct&amp;gt; MALE, FEMALE, FEMALE, FEMALE, MALE, FEMALE, MALE, F‚Ä¶&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;penguins&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;4&lt;/span&gt; Penguins&lt;/h1&gt;
&lt;p&gt;This data included structural size measurements of penguins like their bill length, flipper length, and body mass. It also included each penguin‚Äôs species and sex. I‚Äôm going to use this data to try to predict penguin body mass. Sadly, we only have data for three distinct penguin species:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguins %&amp;gt;% 
  count(species)
#&amp;gt; # A tibble: 3 x 2
#&amp;gt;   species       n
#&amp;gt;   &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;
#&amp;gt; 1 Adelie      146
#&amp;gt; 2 Chinstrap    68
#&amp;gt; 3 Gentoo      119&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a lineup:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.bas.ac.uk/wp-content/uploads/2015/04/Penguin-heights.jpg&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From: &lt;a href=&#34;https://www.bas.ac.uk/about/antarctica/wildlife/penguins/&#34; class=&#34;uri&#34;&gt;https://www.bas.ac.uk/about/antarctica/wildlife/penguins/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Looks like we have data for 3 of the smaller penguin species (of those pictured here).&lt;/p&gt;
&lt;p&gt;First, let‚Äôs build a simple linear regression model to predict body mass from flipper length.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(color = &amp;quot;salmon&amp;quot;, size = 3, alpha = .9) +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  theme_penguin()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;figs/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not bad! Looks promising. To actually fit a linear regression model, you might be used to something like this in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_mod &amp;lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins)
summary(penguin_mod)
#&amp;gt; 
#&amp;gt; Call:
#&amp;gt; lm(formula = body_mass_g ~ flipper_length_mm, data = penguins)
#&amp;gt; 
#&amp;gt; Residuals:
#&amp;gt;      Min       1Q   Median       3Q      Max 
#&amp;gt; -1057.33  -259.79   -12.24   242.97  1293.89 
#&amp;gt; 
#&amp;gt; Coefficients:
#&amp;gt;                   Estimate Std. Error t value Pr(&amp;gt;|t|)    
#&amp;gt; (Intercept)       -5872.09     310.29  -18.93   &amp;lt;2e-16 ***
#&amp;gt; flipper_length_mm    50.15       1.54   32.56   &amp;lt;2e-16 ***
#&amp;gt; ---
#&amp;gt; Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
#&amp;gt; 
#&amp;gt; Residual standard error: 393.3 on 331 degrees of freedom
#&amp;gt; Multiple R-squared:  0.7621, Adjusted R-squared:  0.7614 
#&amp;gt; F-statistic:  1060 on 1 and 331 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But we aren‚Äôt going to stick with this. We are going to use tidymodels, with the goal of generating accurate predictions for future, yet-to-be-seen penguins.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/C0EYVrLCgnYdy/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidymodels-101&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;5&lt;/span&gt; tidymodels 101&lt;/h1&gt;
&lt;p&gt;The code provided in the section below is &lt;em&gt;not&lt;/em&gt; particularly sad üêß. If you are embarking on learning tidymodels, you‚Äôll need to use this same kind of code as the building blocks for any predictive modeling pipeline.&lt;/p&gt;
&lt;div id=&#34;parsnip-build-the-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.1&lt;/span&gt; Parsnip: build the model&lt;/h2&gt;
&lt;p&gt;This step is really three, using only the &lt;a href=&#34;https://tidymodels.github.io/parsnip/&#34;&gt;parsnip package&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_spec &amp;lt;- 
  linear_reg() %&amp;gt;%       # pick model
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;%   # set engine
  set_mode(&amp;quot;regression&amp;quot;) # set mode

lm_spec
#&amp;gt; Linear Regression Model Specification (regression)
#&amp;gt; 
#&amp;gt; Computational engine: lm&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Things that are missing: data (we haven‚Äôt touched it yet) and a formula (no data, no variables, no twiddle &lt;code&gt;~&lt;/code&gt;). This is an &lt;em&gt;abstract&lt;/em&gt; model specification. See other possible parsnip models &lt;a href=&#34;https://tidymodels.github.io/parsnip/articles/articles/Models.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;recipe-not-happening-here-folks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.2&lt;/span&gt; Recipe: not happening here, folks&lt;/h2&gt;
&lt;p&gt;This is where you would normally insert some code for feature engineering using the &lt;a href=&#34;https://tidymodels.github.io/recipes/&#34;&gt;recipes package&lt;/a&gt;. But previously this required functions named &lt;code&gt;prep()&lt;/code&gt;, &lt;code&gt;bake()&lt;/code&gt;, &lt;code&gt;juice()&lt;/code&gt;- so I‚Äôm willfully ignoring that for now. There will be no recipes involving penguins.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/H4uE6w9G1uK4M/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rsample-initial-split&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.3&lt;/span&gt; Rsample: initial split&lt;/h2&gt;
&lt;p&gt;We‚Äôll use the &lt;a href=&#34;https://tidymodels.github.io/rsample/&#34;&gt;rsample package&lt;/a&gt; to split (&lt;em&gt;ayee! I promise no penguins were hurt in the writing of this blog post&lt;/em&gt;) the penguins up into two datasets: training and testing. If you are unfamiliar with this practice, read up on &lt;a href=&#34;https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html#resubstitution-validation-and-the-holdout-method&#34;&gt;the holdout method&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_split &amp;lt;- initial_split(penguins, strata = species)
penguin_train &amp;lt;- training(penguin_split)
penguin_test  &amp;lt;- testing(penguin_split)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model-once&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.4&lt;/span&gt; Fitting the model once&lt;/h2&gt;
&lt;p&gt;Fitting a single model once is‚Ä¶not &lt;em&gt;exactly&lt;/em&gt; the hardest part.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/4KALRmOb8uwbC/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is essentially the workflow from this &lt;a href=&#34;https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/&#34;&gt;early blog post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)

lm_spec %&amp;gt;% 
  
  # train: get fitted model
  fit(body_mass_g ~ ., data = penguin_train) %&amp;gt;% 
  
  # test: get predictions
  predict(new_data = penguin_test) %&amp;gt;% 
  
  # compare: get metrics
  bind_cols(penguin_test) %&amp;gt;% 
  rmse(truth = body_mass_g, estimate = .pred)
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;   .metric .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard        297.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-the-model-with-a-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;5.5&lt;/span&gt; Fitting the model with a function&lt;/h2&gt;
&lt;p&gt;If you squint, you might see that I could make this into a function like below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_rmse &amp;lt;- function(model_spec, split) {
  
  model_spec %&amp;gt;% 
    
    # train: get fitted model
    fit(body_mass_g ~ ., data = training(split)) %&amp;gt;% 
    
    # test: get predictions
    predict(new_data = testing(split)) %&amp;gt;% 
    
    # compare: get metrics
    bind_cols(testing(split)) %&amp;gt;% 
    rmse(truth = body_mass_g, estimate = .pred)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And I could use it to fit a linear regression model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)
get_rmse(model_spec = lm_spec, split = penguin_split)
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;   .metric .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard        297.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I could also build up a tibble that includes the results, if I wanted to save the predicted values, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_preds &amp;lt;- function(model_spec, split){
  
  # train: get fitted model
  fit_model &amp;lt;- model_spec %&amp;gt;% 
    fit(body_mass_g ~ ., data = training(split))
  
  # test: get predictions
  preds &amp;lt;- fit_model %&amp;gt;% 
    predict(new_data = testing(split)) %&amp;gt;% 
    bind_cols(testing(split) %&amp;gt;% select(body_mass_g, species))

  preds
}

set.seed(0)
penguin_preds &amp;lt;- get_preds(model_spec = lm_spec, split = penguin_split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I can work with the predicted values, like plotting the fitted body mass estimates against the residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(penguin_preds, aes(x = .pred, y = (.pred - body_mass_g))) +
  geom_point(aes(colour = species), size = 3, alpha = .8) +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  theme_penguin() +
  scico::scale_colour_scico_d(end = .8) +
  ggtitle(&amp;quot;Residuals vs Fitted&amp;quot;)
#&amp;gt; `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;figs/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
# compare: get metrics
penguin_preds %&amp;gt;% 
  rmse(truth = body_mass_g, estimate = .pred)
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;   .metric .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard        297.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or I could fit a regression tree model with a new model spec:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# regression tree model spec
rt_spec &amp;lt;-
  decision_tree() %&amp;gt;% 
  set_engine(&amp;quot;rpart&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

# get rmse
set.seed(0)
get_preds(model_spec = rt_spec, 
          split = penguin_split) %&amp;gt;% 
  rmse(truth = body_mass_g, estimate = .pred)
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;   .metric .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard        321.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Or a random forest:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# random forest model spec
rf_spec &amp;lt;-
  rand_forest() %&amp;gt;% 
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

# get rmse
set.seed(0)
get_preds(model_spec = rf_spec, 
          split = penguin_split) %&amp;gt;% 
  rmse(truth = body_mass_g, estimate = .pred)
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;   .metric .estimator .estimate
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard        299.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But, unfortunately, I shouldn‚Äôt be predicting with the test set over and over again like this. It isn‚Äôt good practice to predict with the test set &amp;gt; 1 time. What is a good predictive modeler to do? I should be saving (holding out) the test set and use it to generate predictions exactly once, at the very end ‚Äî after I‚Äôve compared different models, selected my features, and tuned my hyperparameters. How do you do this? You do &lt;a href=&#34;https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html&#34;&gt;cross-validation&lt;/a&gt; with the training set, and you leave the testing set for &lt;a href=&#34;https://tidymodels.github.io/tune/reference/last_fit.html&#34;&gt;&lt;em&gt;the very last fit you do&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/uwlDAujt3w9mU/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;hey-jude-dont-make-it-sad&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;6&lt;/span&gt; Hey Jude, don‚Äôt make it sad üé∂&lt;/h1&gt;
&lt;p&gt;Now, for the üò≠ part- let‚Äôs add cross-validation! To do this, we‚Äôll use a function called &lt;a href=&#34;https://tidymodels.github.io/rsample/reference/vfold_cv.html&#34;&gt;&lt;code&gt;rsample::vfold_cv()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# add the cv step here
set.seed(0)
penguin_folds &amp;lt;- vfold_cv(data = penguin_train, strata = &amp;quot;species&amp;quot;)

penguin_folds
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 2
#&amp;gt;    splits           id    
#&amp;gt;    &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt; 
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The process of training, testing, and computing metrics gets a lot harder when you need to do this across 10 folds, each with a different data split. I eventually worked out three approaches, which I show below. All require some level of comfort with iteration using the &lt;a href=&#34;https://purrr.tidyverse.org/&#34;&gt;purrr package&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;function-with-minimal-purrr-ing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.1&lt;/span&gt; Function with minimal purrr-ing&lt;/h2&gt;
&lt;p&gt;This approach is essentially a mega-function, that we then use purrr to map across each fold.&lt;/p&gt;
&lt;p&gt;I‚Äôm going to change a few things from my previous &lt;code&gt;get_preds()&lt;/code&gt; function:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;training(split)&lt;/code&gt; -&amp;gt; &lt;code&gt;analysis(split)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;testing(split)&lt;/code&gt; -&amp;gt; &lt;code&gt;assessment(split)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;I also added the &lt;code&gt;rsample::add_resample_id()&lt;/code&gt; function to keep track of the fold number.&lt;/li&gt;
&lt;li&gt;I saved the predictions now as a list column.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To build up this function, my strategy was to figure out how to work with one fold, then I knew I‚Äôd be able to use &lt;code&gt;purrr::map_df()&lt;/code&gt; to apply it across multiple folds.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Figure it out for one fold
get_fold_results &amp;lt;- function(model_spec, split){
  
  # train: get fitted model for each fold
  fits &amp;lt;- model_spec %&amp;gt;% 
    fit(body_mass_g ~ ., data = analysis(split))
  
  # test: get predictions on for each fold
  preds &amp;lt;- fits %&amp;gt;% 
    predict(new_data = assessment(split)) %&amp;gt;% 
    bind_cols(assessment(split)) 
  
  # compare: compute metric for each fold
  rmse &amp;lt;- assessment(split)  %&amp;gt;% 
    summarize(rmse = rmse_vec(truth = body_mass_g, 
                              estimate = preds$.pred))
  
  rmse %&amp;gt;% 
    # add fold identifier column
    rsample::add_resample_id(split = split) %&amp;gt;% 
    as_tibble() %&amp;gt;% 
    # add predictions
    mutate(preds = list(preds))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I tried this function with a single fold first:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)
get_fold_results(
    split      = penguin_folds$splits[[1]], 
    model_spec = rt_spec
  )
#&amp;gt; # A tibble: 1 x 3
#&amp;gt;    rmse id     preds            
#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;           
#&amp;gt; 1  291. Fold01 &amp;lt;tibble [26 √ó 7]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I used purrr- but just once. The function &lt;code&gt;get_fold_results&lt;/code&gt; is doing &lt;strong&gt;most&lt;/strong&gt; of the work for us, but I needed purrr to map it across each fold.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)
kfold_results &amp;lt;- 
  map_df(
    penguin_folds$splits, 
    ~get_fold_results(.x, model = rt_spec))
kfold_results
#&amp;gt; # A tibble: 10 x 3
#&amp;gt;     rmse id     preds            
#&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;           
#&amp;gt;  1  291. Fold01 &amp;lt;tibble [26 √ó 7]&amp;gt;
#&amp;gt;  2  298. Fold02 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  3  303. Fold03 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  4  359. Fold04 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  5  320. Fold05 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  6  434. Fold06 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  7  320. Fold07 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  8  245. Fold08 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  9  262. Fold09 &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt; 10  343. Fold10 &amp;lt;tibble [25 √ó 7]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we are still left with 10 RMSE values- one for each of the 10 folds. We don‚Äôt care too much about by fold- the power is in the aggregate. Specifically, we mainly care about the central tendency and spread of these RMSE values. Let‚Äôs finish by combining (or aggregating) these metrics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kfold_results %&amp;gt;% 
  summarize(mean_rmse = mean(rmse), sd_rmse = sd(rmse))
#&amp;gt; # A tibble: 1 x 2
#&amp;gt;   mean_rmse sd_rmse
#&amp;gt;       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt; 1      317.    53.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, this works. But, can you imagine doing it again? Without errors? Can you imagine teaching it?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/bmGmHZ5khMjN6/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;purrr-to-the-max&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.2&lt;/span&gt; Purrr-to-the-max&lt;/h2&gt;
&lt;p&gt;This approach is &lt;code&gt;purrr::map()&lt;/code&gt; (and friends) on steriods. We use vanilla &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;map2()&lt;/code&gt;, &lt;em&gt;and&lt;/em&gt; &lt;code&gt;map2_dbl()&lt;/code&gt; here. We also use &lt;a href=&#34;https://jennybc.github.io/purrr-tutorial/ls03_map-function-syntax.html#anonymous_function,_formula&#34;&gt;anonymous functions as a formula&lt;/a&gt;, &lt;em&gt;and&lt;/em&gt; the pipe operator within those anonymous functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)
penguin_res &amp;lt;- penguin_folds %&amp;gt;% 
  mutate(
    
    # train: get fitted model for each fold
    train_set  = map(splits, analysis),
    fit_models = map(train_set, ~rt_spec %&amp;gt;% 
                                    fit(body_mass_g ~ ., 
                                        data = .x)),
    
    # test: get predictions for each fold
    test_set   = map(splits, assessment),
    estimates  = map2(fit_models, 
                      test_set, 
                      ~.x %&amp;gt;% 
                        predict(.y)),
    
    # compare: compute metric for each fold
    rmse       = map2_dbl(test_set, 
                          estimates, 
                          ~rmse_vec(truth = .x$body_mass_g, 
                                    estimate = .y$.pred))
  )

penguin_res
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 7
#&amp;gt;    splits      id     train_set      fit_models  test_set     estimates     rmse
#&amp;gt;  * &amp;lt;named lis&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;named list&amp;gt;   &amp;lt;named lis&amp;gt; &amp;lt;named list&amp;gt; &amp;lt;named list&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt;  1 &amp;lt;split [22‚Ä¶ Fold01 &amp;lt;tibble [225 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [26‚Ä¶ &amp;lt;tibble [26‚Ä¶  291.
#&amp;gt;  2 &amp;lt;split [22‚Ä¶ Fold02 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  298.
#&amp;gt;  3 &amp;lt;split [22‚Ä¶ Fold03 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  303.
#&amp;gt;  4 &amp;lt;split [22‚Ä¶ Fold04 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  359.
#&amp;gt;  5 &amp;lt;split [22‚Ä¶ Fold05 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  320.
#&amp;gt;  6 &amp;lt;split [22‚Ä¶ Fold06 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  434.
#&amp;gt;  7 &amp;lt;split [22‚Ä¶ Fold07 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  320.
#&amp;gt;  8 &amp;lt;split [22‚Ä¶ Fold08 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  245.
#&amp;gt;  9 &amp;lt;split [22‚Ä¶ Fold09 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  262.
#&amp;gt; 10 &amp;lt;split [22‚Ä¶ Fold10 &amp;lt;tibble [226 ‚Ä¶ &amp;lt;fit[+]&amp;gt;    &amp;lt;tibble [25‚Ä¶ &amp;lt;tibble [25‚Ä¶  343.

penguin_res %&amp;gt;% 
  summarise(mean_rmse = mean(rmse), sd_rmse = sd(rmse))
#&amp;gt; # A tibble: 1 x 2
#&amp;gt;   mean_rmse sd_rmse
#&amp;gt;       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt; 1      317.    53.4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-purrr-mash-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.3&lt;/span&gt; The purrr mash-up&lt;/h2&gt;
&lt;p&gt;Another way I worked out was largely after reviewing Max‚Äôs slides from previous workshops. This is basically a mash-up of my previous two approaches, where we write laser-focused functions that each do one thing, then use purrr to apply those functions across the folds. This way is nice(r) for showing in slides as you can incrementally build up the results table. Let‚Äôs see this sad script in action‚Ä¶&lt;/p&gt;
&lt;div id=&#34;round-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.3.1&lt;/span&gt; Round 1&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0) # for reproducibility

# train: get fitted model for a split
get_fits &amp;lt;- function(split, model_spec){
  model_spec %&amp;gt;% 
    fit(body_mass_g ~ ., 
        data = analysis(split))
}

# train: get fitted models across folds
penguin_purrr &amp;lt;- penguin_folds %&amp;gt;% 
  mutate(rt_fits = map(splits, get_fits, rt_spec))

penguin_purrr
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 3
#&amp;gt;    splits           id     rt_fits     
#&amp;gt;  * &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;named list&amp;gt;
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08 &amp;lt;fit[+]&amp;gt;    
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09 &amp;lt;fit[+]&amp;gt;    
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10 &amp;lt;fit[+]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;round-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.3.2&lt;/span&gt; Round 2&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# test: get predictions for a split
get_preds &amp;lt;- function(split, fit_df) {
  
  fit_df %&amp;gt;% 
    predict(new_data = assessment(split)) %&amp;gt;% 
    bind_cols(assessment(split))
  
}

# test: get predictions across folds
penguin_purrr &amp;lt;- penguin_purrr %&amp;gt;% 
  mutate(rt_preds = map2(splits, rt_fits, get_preds))

penguin_purrr
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 4
#&amp;gt;    splits           id     rt_fits      rt_preds         
#&amp;gt;  * &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;named list&amp;gt; &amp;lt;named list&amp;gt;     
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [26 √ó 7]&amp;gt;
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;aaaand-round-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;6.3.3&lt;/span&gt; aaaand Round 3&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# compare: compute metric for a split
get_rmse &amp;lt;- function(pred_df) {
  
  pred_df %&amp;gt;% 
    rmse(truth    = body_mass_g, 
         estimate = .pred) %&amp;gt;% 
    pluck(&amp;quot;.estimate&amp;quot;)
  
}

# compare: compute metric across folds
penguin_purrr &amp;lt;- penguin_purrr %&amp;gt;% 
  mutate(rt_rmse = map_dbl(rt_preds, get_rmse))

penguin_purrr
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 5
#&amp;gt;    splits           id     rt_fits      rt_preds          rt_rmse
#&amp;gt;  * &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;named list&amp;gt; &amp;lt;named list&amp;gt;        &amp;lt;dbl&amp;gt;
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [26 √ó 7]&amp;gt;    291.
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    298.
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    303.
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    359.
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    320.
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    434.
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    320.
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    245.
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    262.
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    343.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, summarizing as I did before:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_purrr %&amp;gt;% 
  summarize(mean_rmse = mean(rt_rmse), sd_rmse = sd(rt_rmse))
#&amp;gt; # A tibble: 1 x 2
#&amp;gt;   mean_rmse sd_rmse
#&amp;gt;       &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt; 1      317.    53.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In practice, if you did all these at once instead of incrementally, it would look like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(0)
penguin_folds %&amp;gt;% 
  
  # train: get fitted model for a split
  mutate(rt_fits = map(splits, get_fits, rt_spec)) %&amp;gt;% 
  
  # test: get predictions on for each fold
  mutate(rt_preds = map2(splits, rt_fits, get_preds)) %&amp;gt;% 
  
  # compare: compute metric for each fold
  mutate(rt_rmse = map_dbl(rt_preds, get_rmse))
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 5
#&amp;gt;    splits           id     rt_fits      rt_preds          rt_rmse
#&amp;gt;  * &amp;lt;named list&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;named list&amp;gt; &amp;lt;named list&amp;gt;        &amp;lt;dbl&amp;gt;
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [26 √ó 7]&amp;gt;    291.
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    298.
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    303.
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    359.
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    320.
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    434.
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    320.
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    245.
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    262.
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10 &amp;lt;fit[+]&amp;gt;     &amp;lt;tibble [25 √ó 7]&amp;gt;    343.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you put it like &lt;em&gt;that&lt;/em&gt;, it doesn‚Äôt look like so much work! But, this way hides how much work it takes to write those 3 custom functions: &lt;code&gt;get_fits()&lt;/code&gt;, &lt;code&gt;get_preds()&lt;/code&gt;, and &lt;code&gt;get_rmse()&lt;/code&gt;. And we still had to use vanilla &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;map2()&lt;/code&gt;, &lt;em&gt;and&lt;/em&gt; &lt;code&gt;map2_dbl()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;make-it-better&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;7&lt;/span&gt; Make it better&lt;/h1&gt;
&lt;p&gt;I kept a learning log while working through the all the above code, and I wrote down these notes to myself:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;It is very easy to do the wrong thing; it is very hard to do the right thing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I lost sight many times of what the code I was writing was doing, because I was using up so much cognitive energy on getting the code to just work.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I thought I knew how to use purrr‚Ä¶&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you have made it this far, I‚Äôm pretty sure I don‚Äôt need to convince you that a better way to do cross-validation using tidymodels would be more pleasant to do more than once. It would also be less prone to error due to me copying-and-pasting repeatedly, and making stupid mistakes that would be difficult to spot with so much cluttered code. Luckily, &lt;a href=&#34;https://tidymodels.github.io/tune/reference/fit_resamples.html&#34;&gt;&lt;code&gt;tune::fit_resamples()&lt;/code&gt;&lt;/a&gt; came along to take a sad script and make it better:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_party &amp;lt;-
  tune::fit_resamples(
    body_mass_g ~ .,
    model = rt_spec,
    resamples = penguin_folds
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the beautiful output from that function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_party
#&amp;gt; #  10-fold cross-validation using stratification 
#&amp;gt; # A tibble: 10 x 4
#&amp;gt;    splits           id     .metrics         .notes          
#&amp;gt;  * &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;  &amp;lt;list&amp;gt;           &amp;lt;list&amp;gt;          
#&amp;gt;  1 &amp;lt;split [225/26]&amp;gt; Fold01 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  2 &amp;lt;split [226/25]&amp;gt; Fold02 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  3 &amp;lt;split [226/25]&amp;gt; Fold03 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  4 &amp;lt;split [226/25]&amp;gt; Fold04 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  5 &amp;lt;split [226/25]&amp;gt; Fold05 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  6 &amp;lt;split [226/25]&amp;gt; Fold06 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  7 &amp;lt;split [226/25]&amp;gt; Fold07 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  8 &amp;lt;split [226/25]&amp;gt; Fold08 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt;  9 &amp;lt;split [226/25]&amp;gt; Fold09 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;
#&amp;gt; 10 &amp;lt;split [226/25]&amp;gt; Fold10 &amp;lt;tibble [2 √ó 3]&amp;gt; &amp;lt;tibble [0 √ó 1]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, to see all the stuff inside this &lt;code&gt;penguin_party&lt;/code&gt;, we can use tune‚Äôs &lt;code&gt;collect_*&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_party %&amp;gt;% 
  collect_metrics()
#&amp;gt; # A tibble: 2 x 5
#&amp;gt;   .metric .estimator    mean     n std_err
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt; 1 rmse    standard   317.       10 16.9   
#&amp;gt; 2 rsq     standard     0.827    10  0.0303&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see the predictions, we need to add use &lt;a href=&#34;https://tidymodels.github.io/tune/reference/control_grid.html&#34;&gt;&lt;code&gt;control_resamples()&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_party &amp;lt;-
  tune::fit_resamples(
    body_mass_g ~ .,
    model = rt_spec,
    resamples = penguin_folds,
    control = control_resamples(save_pred = TRUE) # add this line
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we collect the predictions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;penguin_party %&amp;gt;% 
  collect_predictions()
#&amp;gt; # A tibble: 251 x 4
#&amp;gt;    id     .pred  .row body_mass_g
#&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;       &amp;lt;dbl&amp;gt;
#&amp;gt;  1 Fold01 4040.     4        4675
#&amp;gt;  2 Fold01 3428.    11        3800
#&amp;gt;  3 Fold01 3428.    14        3200
#&amp;gt;  4 Fold01 4040.    41        3750
#&amp;gt;  5 Fold01 4040.    54        3900
#&amp;gt;  6 Fold01 3428.    65        3400
#&amp;gt;  7 Fold01 3428.    70        2900
#&amp;gt;  8 Fold01 4040.    71        4100
#&amp;gt;  9 Fold01 3428.    76        2925
#&amp;gt; 10 Fold01 4040.    85        3775
#&amp;gt; # ‚Ä¶ with 241 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, isn‚Äôt that better?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/daeKl3P4SissU/giphy.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
